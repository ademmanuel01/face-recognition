{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b3ed0d",
   "metadata": {},
   "source": [
    "## Use of face_recognition library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930960fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the Color photo files are...\n",
      "photo1 Photo.... (1024, 769, 3)\n",
      "photo2 Photo..... (1024, 769, 3)\n",
      "photo3 Photo...... (1024, 769, 3)\n"
     ]
    }
   ],
   "source": [
    "#loading of images and check for the image shape\n",
    "\n",
    "import face_recognition\n",
    "photo1 = face_recognition.load_image_file('./pic1.jpeg','RGB')\n",
    "photo2 = face_recognition.load_image_file('./pic2.jpeg','RGB')\n",
    "photo3 = face_recognition.load_image_file('./pic3.jpeg')\n",
    "print(\"The shapes of the Color photo files are...\")\n",
    "print(\"photo1 Photo....\",photo1.shape)\n",
    "print(\"photo2 Photo.....\", photo2.shape)\n",
    "print(\"photo3 Photo......\", photo3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7ad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the bw photo files are...\n",
      "photoA Photo.... (1024, 769)\n",
      "photoB Photo..... (1024, 769)\n",
      "photoC Photo...... (1024, 769)\n"
     ]
    }
   ],
   "source": [
    "# we want to load the files in Black and White format we must use using 'L'\n",
    "# attribute in the second attribute of load_image_file() function as follows:\n",
    "\n",
    "photoA = face_recognition.load_image_file('./pic1.jpeg','L')\n",
    "photoB = face_recognition.load_image_file('./pic2.jpeg','L')\n",
    "photoC = face_recognition.load_image_file('./pic3.jpeg', 'L')\n",
    "print(\"The shapes of the bw photo files are...\")\n",
    "print(\"photoA Photo....\",photoA.shape)\n",
    "print(\"photoB Photo.....\", photoB.shape)\n",
    "print(\"photoC Photo......\", photoC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf1403",
   "metadata": {},
   "source": [
    "## Python Image Library\n",
    "\n",
    "Python Image Library (PIL) is a opensource library for Python that supports image processing\n",
    "activities of pictures, including the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c525a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "# photo1 = face_recognition.load_image_file('./pic1.jpeg','RGB')\n",
    "# photo2 = face_recognition.load_image_file('./pic2.jpeg','RGB')\n",
    "# photo3 = face_recognition.load_image_file('./pic3.jpeg')\n",
    "pil_image1 = Image.fromarray(photo1)\n",
    "pil_image1.show()\n",
    "pil_image2 = Image.fromarray(photo2)\n",
    "pil_image2.show()\n",
    "pil_image3 = Image.fromarray(photo3)\n",
    "pil_image3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb131fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image1 = Image.fromarray(photoA)\n",
    "pil_image1.show()\n",
    "pil_image2 = Image.fromarray(photoB)\n",
    "pil_image2.show()\n",
    "pil_image3 = Image.fromarray(photoC)\n",
    "pil_image3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73655de2",
   "metadata": {},
   "source": [
    "## Face Locations Method\n",
    "\n",
    "In python face-recognition library, face_locations() method detects all human faces in the image.\n",
    "Each face is detected as a rectangular frame in the form of a tuple (top,left,bottom,right). If there are n faces, the output is a list of n tuples with four entries as (top, right, bottom, left)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8720e2a",
   "metadata": {},
   "source": [
    "## HOG (Histogram Oriented Gradient) Approach.\n",
    "\n",
    "In detecting the faces and locating the rectangular frames HOG (Histogram Oriented Gradient) Approach. This is faster but less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af17e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(376, 546, 761, 161), (580, 184, 735, 29)]\n",
      "(1024, 769, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "test_pic3 = face_recognition.load_image_file('./pic3.jpeg')\n",
    "print(test_pic3.shape)\n",
    "l = face_recognition.face_locations(test_pic3, model = 'hog')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "pic3_face = test_pic3[top:bottom, left:right]\n",
    "print(test_pic3.shape)\n",
    "pic3_face_image = Image.fromarray(pic3_face)\n",
    "pic3_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef633f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  5 face(s) in this photo\n",
      "Face 1...Top: 136, Left: 772, Bottom: 226, Right: 862\n",
      "Face 2...Top: 130, Left: 536, Bottom: 204, Right: 610\n",
      "Face 3...Top: 188, Left: 386, Bottom: 262, Right: 461\n",
      "Face 4...Top: 175, Left: 223, Bottom: 218, Right: 266\n",
      "Face 5...Top: 130, Left: 406, Bottom: 182, Right: 458\n"
     ]
    }
   ],
   "source": [
    "#Face Detection using HOG Model \n",
    "\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./group1.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"hog\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b6145",
   "metadata": {},
   "source": [
    "## Deep Learning based Convolution Neural Network (CNN) Approach.\n",
    "\n",
    "CNN is more accurate but it takes more time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1193ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(386, 506, 739, 154), (560, 196, 729, 26)]\n",
      "(353, 352, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "test2_photo = face_recognition.load_image_file('./pic3.jpeg')\n",
    "print(test2_photo.shape)\n",
    "l = face_recognition.face_locations(test2_photo, model ='cnn')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "test2_image = test2_photo[top:bottom, left:right]\n",
    "print(test2_image.shape)\n",
    "test2_face_image = Image.fromarray(test2_image)\n",
    "test2_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a22ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  8 face(s) in this photo\n",
      "Face 1...Top: 163, Left: 35, Bottom: 210, Right: 82\n",
      "Face 2...Top: 135, Left: 783, Bottom: 203, Right: 852\n",
      "Face 3...Top: 137, Left: 555, Bottom: 194, Right: 611\n",
      "Face 4...Top: 183, Left: 376, Bottom: 252, Right: 444\n",
      "Face 5...Top: 211, Left: 318, Bottom: 258, Right: 365\n",
      "Face 6...Top: 173, Left: 217, Bottom: 220, Right: 264\n",
      "Face 7...Top: 129, Left: 414, Bottom: 177, Right: 461\n",
      "Face 8...Top: 177, Left: 884, Bottom: 225, Right: 932\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning based Convolution Neural Network (CNN) approach. CNN\n",
    "# is more accurate but it takes more time to compute.\n",
    "\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./group1.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"cnn\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d43da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2 face(s) in this photo\n",
      "Face 1...Top: 386, Left: 154, Bottom: 739, Right: 506\n",
      "Face 2...Top: 560, Left: 26, Bottom: 729, Right: 196\n"
     ]
    }
   ],
   "source": [
    "group_photo = face_recognition.load_image_file(\"./pic3.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"cnn\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b9f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a559ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c04b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b1896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1b34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
