{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b3ed0d",
   "metadata": {},
   "source": [
    "## Use of face_recognition library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930960fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the Color photo files are...\n",
      "photo1 Photo.... (1024, 769, 3)\n",
      "photo2 Photo..... (1024, 769, 3)\n",
      "photo3 Photo...... (1024, 769, 3)\n"
     ]
    }
   ],
   "source": [
    "#loading of images and check for the image shape\n",
    "\n",
    "import face_recognition\n",
    "photo1 = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "photo2 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "photo3 = face_recognition.load_image_file('./pics&group/pic3.jpeg')\n",
    "print(\"The shapes of the Color photo files are...\")\n",
    "print(\"photo1 Photo....\",photo1.shape)\n",
    "print(\"photo2 Photo.....\", photo2.shape)\n",
    "print(\"photo3 Photo......\", photo3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7ad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the bw photo files are...\n",
      "photoA Photo.... (1024, 769)\n",
      "photoB Photo..... (1024, 769)\n",
      "photoC Photo...... (1024, 769)\n"
     ]
    }
   ],
   "source": [
    "# we want to load the files in Black and White format we must use using 'L'\n",
    "# attribute in the second attribute of load_image_file() function as follows:\n",
    "\n",
    "photoA = face_recognition.load_image_file('./pics&group/pic1.jpeg','L')\n",
    "photoB = face_recognition.load_image_file('./pics&group/pic2.jpeg','L')\n",
    "photoC = face_recognition.load_image_file('./pics&group/pic3.jpeg', 'L')\n",
    "print(\"The shapes of the bw photo files are...\")\n",
    "print(\"photoA Photo....\",photoA.shape)\n",
    "print(\"photoB Photo.....\", photoB.shape)\n",
    "print(\"photoC Photo......\", photoC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf1403",
   "metadata": {},
   "source": [
    "## Python Image Library\n",
    "\n",
    "Python Image Library (PIL) is a opensource library for Python that supports image processing\n",
    "activities of pictures, including the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c525a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "pil_image1 = Image.fromarray(photo1)\n",
    "pil_image1.show()\n",
    "pil_image2 = Image.fromarray(photo2)\n",
    "pil_image2.show()\n",
    "pil_image3 = Image.fromarray(photo3)\n",
    "pil_image3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb131fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image1 = Image.fromarray(photoA)\n",
    "pil_image1.show()\n",
    "pil_image2 = Image.fromarray(photoB)\n",
    "pil_image2.show()\n",
    "pil_image3 = Image.fromarray(photoC)\n",
    "pil_image3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73655de2",
   "metadata": {},
   "source": [
    "## Face Locations Method\n",
    "\n",
    "In python face-recognition library, face_locations() method detects all human faces in the image.\n",
    "Each face is detected as a rectangular frame in the form of a tuple (top,left,bottom,right). If there are n faces, the output is a list of n tuples with four entries as (top, right, bottom, left)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8720e2a",
   "metadata": {},
   "source": [
    "## HOG (Histogram Oriented Gradient) Approach.\n",
    "\n",
    "In detecting the faces and locating the rectangular frames HOG (Histogram Oriented Gradient) Approach. This is faster but less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af17e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(376, 546, 761, 161), (580, 184, 735, 29)]\n",
      "(1024, 769, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "test_pic3 = face_recognition.load_image_file('./pics&group/pic3.jpeg')\n",
    "print(test_pic3.shape)\n",
    "l = face_recognition.face_locations(test_pic3, model = 'hog')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "pic3_face = test_pic3[top:bottom, left:right]\n",
    "print(test_pic3.shape)\n",
    "pic3_face_image = Image.fromarray(pic3_face)\n",
    "pic3_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef633f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  5 face(s) in this photo\n",
      "Face 1...Top: 136, Left: 772, Bottom: 226, Right: 862\n",
      "Face 2...Top: 130, Left: 536, Bottom: 204, Right: 610\n",
      "Face 3...Top: 188, Left: 386, Bottom: 262, Right: 461\n",
      "Face 4...Top: 175, Left: 223, Bottom: 218, Right: 266\n",
      "Face 5...Top: 130, Left: 406, Bottom: 182, Right: 458\n"
     ]
    }
   ],
   "source": [
    "#Face Detection using HOG Model \n",
    "\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"hog\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b6145",
   "metadata": {},
   "source": [
    "## Deep Learning based Convolution Neural Network (CNN) Approach.\n",
    "\n",
    "CNN is more accurate but it takes more time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1193ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(386, 506, 739, 154), (560, 196, 729, 26)]\n",
      "(353, 352, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "test2_photo = face_recognition.load_image_file('./pics&group/pic3.jpeg')\n",
    "print(test2_photo.shape)\n",
    "l = face_recognition.face_locations(test2_photo, model ='cnn')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "test2_image = test2_photo[top:bottom, left:right]\n",
    "print(test2_image.shape)\n",
    "test2_face_image = Image.fromarray(test2_image)\n",
    "test2_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a22ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  8 face(s) in this photo\n",
      "Face 1...Top: 163, Left: 35, Bottom: 210, Right: 82\n",
      "Face 2...Top: 135, Left: 783, Bottom: 203, Right: 852\n",
      "Face 3...Top: 137, Left: 555, Bottom: 194, Right: 611\n",
      "Face 4...Top: 183, Left: 376, Bottom: 252, Right: 444\n",
      "Face 5...Top: 211, Left: 318, Bottom: 258, Right: 365\n",
      "Face 6...Top: 173, Left: 217, Bottom: 220, Right: 264\n",
      "Face 7...Top: 129, Left: 414, Bottom: 177, Right: 461\n",
      "Face 8...Top: 177, Left: 884, Bottom: 225, Right: 932\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning based Convolution Neural Network (CNN) approach. CNN\n",
    "# is more accurate but it takes more time to compute.\n",
    "\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"cnn\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d43da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2 face(s) in this photo\n",
      "Face 1...Top: 386, Left: 154, Bottom: 739, Right: 506\n",
      "Face 2...Top: 560, Left: 26, Bottom: 729, Right: 196\n"
     ]
    }
   ],
   "source": [
    "group_photo = face_recognition.load_image_file(\"./pics&group/pic3.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"cnn\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24b176",
   "metadata": {},
   "source": [
    " ## Locate Faces and Mark with rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a559ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(333, 675, 718, 290)]\n",
      "(385, 385, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "test_photo = face_recognition.load_image_file('./pics&group/pic5.jpeg')\n",
    "print(test_photo.shape)\n",
    "l = face_recognition.face_locations(test_photo)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "test_face = test_photo[top:bottom, left:right]\n",
    "print(test_face.shape)\n",
    "test_face_image = Image.fromarray(test_face)\n",
    "#text_face_image.show()\n",
    "test_photo_image = Image.fromarray(test_photo)\n",
    "draw = ImageDraw.Draw(test_photo_image)\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline = (0, 0, 255), width = 5)\n",
    "test_photo_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbddd9",
   "metadata": {},
   "source": [
    "## Writing text on a Face Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81089499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting art\n",
      "\n",
      "  Downloading art-5.3-py2.py3-none-any.whl (574 kB)\n",
      "Installing collected packages: art\n",
      "Successfully installed art-5.3\n"
     ]
    }
   ],
   "source": [
    "pip install art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5b1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(333, 675, 718, 290)]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "photo_text = face_recognition.load_image_file('./pics&group/pic5.jpeg')\n",
    "print(photo_text.shape)\n",
    "l = face_recognition.face_locations(photo_text)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "\n",
    "\n",
    "#text_face_image.show()\n",
    "text_photo_image = Image.fromarray(photo_text)\n",
    "draw = ImageDraw.Draw(text_photo_image)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 28, encoding=\"unic\")\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline=(0, 0, 255), width = 4)\n",
    "draw.text((left+100,bottom - 50), \"Text on Image\", font=font, fill=(255,128,0))\n",
    "text_photo_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bdb63",
   "metadata": {},
   "source": [
    "## Locate all faces in a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c257a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Faces detected in this photo 8\n",
      "Face,, 0  Top, Left, , Bottom, Right.. 163 35 210 82\n",
      "Face,, 1  Top, Left, , Bottom, Right.. 135 783 203 852\n",
      "Face,, 2  Top, Left, , Bottom, Right.. 137 555 194 611\n",
      "Face,, 3  Top, Left, , Bottom, Right.. 183 376 252 444\n",
      "Face,, 4  Top, Left, , Bottom, Right.. 211 318 258 365\n",
      "Face,, 5  Top, Left, , Bottom, Right.. 173 217 220 264\n",
      "Face,, 6  Top, Left, , Bottom, Right.. 129 414 177 461\n",
      "Face,, 7  Top, Left, , Bottom, Right.. 177 884 225 932\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Convert the group photo into a PIL Image\n",
    "group_pil_image = Image.fromarray(group_photo)\n",
    "\n",
    "# Find all the faces in the image \n",
    "fl = face_recognition.face_locations(group_photo, model = 'cnn')\n",
    "draw = ImageDraw.Draw(group_pil_image)\n",
    "\n",
    "\n",
    "\n",
    "# Let us print the number of faces in the Photo\n",
    "face_count = len(fl)\n",
    "print(\"No of Faces detected in this photo\", face_count)\n",
    "\n",
    "for i in range(face_count):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = fl[i]\n",
    "    print(\"Face,,\", i, \" Top, Left, , Bottom, Right..\", top, left, bottom, right)\n",
    "    # You can access the actual face itself like this:\n",
    "    draw.rectangle(\n",
    "            (left, top, right, bottom),\n",
    "            outline=(255, 0, 0), width=3)\n",
    "        \n",
    "group_pil_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae3ad05",
   "metadata": {},
   "source": [
    "## Writing name on all faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305be530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Faces detected in this photo 8\n",
      "Face,, 0  Top, Left, , Bottom, Right.. 163 35 210 82\n",
      "Face,, 1  Top, Left, , Bottom, Right.. 135 783 203 852\n",
      "Face,, 2  Top, Left, , Bottom, Right.. 137 555 194 611\n",
      "Face,, 3  Top, Left, , Bottom, Right.. 183 376 252 444\n",
      "Face,, 4  Top, Left, , Bottom, Right.. 211 318 258 365\n",
      "Face,, 5  Top, Left, , Bottom, Right.. 173 217 220 264\n",
      "Face,, 6  Top, Left, , Bottom, Right.. 129 414 177 461\n",
      "Face,, 7  Top, Left, , Bottom, Right.. 177 884 225 932\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "grp_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Convert the group photo into a PIL Image\n",
    "grp_pil_image = Image.fromarray(grp_photo)\n",
    "\n",
    "# Find all the faces in the image \n",
    "fl = face_recognition.face_locations(grp_photo, model ='cnn')\n",
    "# Let us print the number of faces in the Photo\n",
    "face_count = len(fl)\n",
    "print(\"No of Faces detected in this photo\", face_count)\n",
    "\n",
    "draw = ImageDraw.Draw(grp_pil_image)\n",
    "\n",
    "fnt = ImageFont.truetype(\"calibri.ttf\", 28, encoding=\"unic\")\n",
    "# Let us print the number of faces in the Photo\n",
    "\n",
    "for i in range(face_count):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = fl[i]\n",
    "    print(\"Face,,\", i, \" Top, Left, , Bottom, Right..\", top, left, bottom, right)\n",
    "    # You can access the actual face itself like this:\n",
    "    draw.rectangle(\n",
    "            (left, top, right, bottom),\n",
    "            outline=(255, 0, 0), width = 3)\n",
    "    draw.text((left,bottom-20), str(i), font=fnt, fill=(0,0,255))   \n",
    "grp_pil_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b157407",
   "metadata": {},
   "source": [
    "## Face encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e70c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the Encoding array is ... (128,)\n",
      "Now let us print the encoding\n",
      "[-2.11196303e-01  1.78484723e-01  1.11796908e-01 -3.69675346e-02\n",
      " -2.81905085e-02 -7.96913281e-02  2.95548178e-02 -6.80622309e-02\n",
      "  1.18464306e-01  3.97704542e-02  2.61571705e-01 -4.08349298e-02\n",
      " -2.01663181e-01 -1.86527967e-01  1.27971441e-01  1.42350957e-01\n",
      " -1.49539962e-01 -7.07360655e-02 -5.49269170e-02 -1.37426510e-01\n",
      "  1.79726519e-02  4.34840657e-02  4.31205854e-02  9.45459157e-02\n",
      " -3.19219604e-02 -4.02293891e-01 -8.23119879e-02 -1.75026685e-01\n",
      "  9.38636884e-02 -8.30285996e-02  4.03862819e-02  1.10961404e-02\n",
      " -2.03860983e-01 -6.13673441e-02 -4.40345928e-02  1.05566584e-01\n",
      "  2.47344486e-02 -2.93298531e-02  1.55784652e-01 -7.25218095e-04\n",
      " -8.27835128e-02 -4.86381724e-02 -2.85921860e-02  2.58049905e-01\n",
      "  1.73459381e-01 -2.19700485e-02  8.15376416e-02  3.18488553e-02\n",
      "  5.31721041e-02 -1.66757688e-01  1.08115096e-02  1.21095069e-01\n",
      "  1.49202660e-01  3.57866846e-02 -2.72658207e-02 -1.29513174e-01\n",
      " -2.14305073e-02  3.06825992e-02 -2.68639117e-01 -6.23787008e-03\n",
      "  4.09384035e-02 -1.01267800e-01 -1.44170463e-01  3.18438672e-02\n",
      "  2.99706817e-01  1.40618727e-01 -1.29726693e-01 -1.26570374e-01\n",
      "  1.63345605e-01 -1.02607056e-01  3.80423367e-02  8.59390125e-02\n",
      " -1.56206667e-01 -8.69053453e-02 -2.27369979e-01  1.58235371e-01\n",
      "  3.36202502e-01 -2.35818420e-03 -2.19868183e-01 -2.62590162e-02\n",
      " -2.59835005e-01  2.45624259e-02 -6.02696426e-02  3.28188203e-02\n",
      " -6.86261654e-02  1.88135281e-02 -1.52100682e-01  8.11169744e-02\n",
      "  7.62470067e-02 -5.84443957e-02  2.88371649e-02  2.46335030e-01\n",
      "  3.45875472e-02  6.64869770e-02 -9.36752837e-03  4.86240350e-02\n",
      " -4.36877944e-02 -3.84113677e-02 -2.95996778e-02 -4.21001874e-02\n",
      "  1.03185520e-01 -7.51372650e-02  7.29914056e-03  6.24471158e-02\n",
      " -2.41833836e-01  1.73316538e-01  4.42830585e-02 -4.67790430e-03\n",
      " -3.25601362e-03 -2.67865304e-02 -2.72489004e-02 -7.65059888e-02\n",
      "  1.70691982e-01 -2.20809340e-01  1.84101537e-01  1.95314333e-01\n",
      " -6.23104423e-02  1.68207467e-01 -2.57039033e-02  1.01060376e-01\n",
      " -5.30466437e-02 -1.05950266e-01 -1.00979976e-01  4.89451503e-03\n",
      "  5.12025580e-02 -1.90983992e-04 -5.21356277e-02  3.34438756e-02]\n"
     ]
    }
   ],
   "source": [
    "#Program to load a picture and find its face encoding\n",
    "import face_recognition\n",
    "photo_emma = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "encodings_emma = face_recognition.face_encodings(photo_emma)[0]\n",
    "print(\"The shapes of the Encoding array is ...\", encodings_emma.shape)\n",
    "print(\"Now let us print the encoding\")\n",
    "print(encodings_emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6866dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of faces  ... 5\n",
      "The shape of each encodings.. (128,)\n",
      "Now let us print the encoding\n",
      " Encodings of Face... 0\n",
      "[-0.16851413  0.10951909  0.09130862 -0.00648152 -0.04712614 -0.09275217\n",
      "  0.11184111 -0.01224661  0.16049841  0.00345446  0.28697512 -0.0394378\n",
      " -0.19605157 -0.06900647  0.04252433  0.11760568 -0.16608121 -0.06631181\n",
      " -0.0669986  -0.16470782  0.01836197  0.03297566 -0.0607566   0.11454876\n",
      " -0.01997722 -0.27992588 -0.10438471 -0.18017244  0.08362632 -0.06120595\n",
      "  0.07091173  0.04499901 -0.12710778 -0.100105   -0.02111205 -0.04602595\n",
      "  0.05683868 -0.03351158  0.19145587  0.04520325 -0.08333259 -0.0273391\n",
      " -0.03052833  0.33285275  0.15645711 -0.02413912  0.04633876  0.03644516\n",
      "  0.07724839 -0.19944479 -0.01383691  0.12738112  0.17862241  0.03740514\n",
      " -0.05250606 -0.12228778 -0.04824601  0.01925332 -0.21925557  0.035402\n",
      "  0.09511295 -0.12231942 -0.11125809 -0.03407955  0.27352944  0.11860164\n",
      " -0.10853916 -0.2043923   0.20215978 -0.14921896 -0.05338492  0.08789917\n",
      " -0.17399178 -0.05273791 -0.21308133  0.16724242  0.376127    0.04397706\n",
      " -0.14772919  0.01088198 -0.29975367  0.07104406 -0.05109765  0.00594479\n",
      " -0.05344229 -0.01733142 -0.09900592 -0.01113193  0.12379471 -0.03586157\n",
      " -0.06822795  0.1905096   0.00658482  0.0004856   0.02519486 -0.03562113\n",
      " -0.00710092 -0.03401057 -0.03461206  0.00072089  0.02932224 -0.0893084\n",
      "  0.03148471  0.06439192 -0.24587652  0.16013055 -0.01557966  0.01927731\n",
      " -0.01904937  0.04271351 -0.10398437 -0.01455203  0.20686866 -0.23258422\n",
      "  0.19558582  0.14211875  0.03380458  0.11872339 -0.00586382  0.07824831\n",
      " -0.07361543 -0.04937768 -0.10842925 -0.03799238  0.06367793 -0.02077905\n",
      " -0.01221005  0.01997939]\n",
      " Encodings of Face... 1\n",
      "[-0.18643883  0.14559843  0.11746334 -0.02375774 -0.10411857 -0.04675899\n",
      " -0.00047594 -0.1377154   0.16327912 -0.04880083  0.30365768 -0.06684311\n",
      " -0.21939391 -0.18909642  0.02387319  0.09889382 -0.17790186 -0.16299903\n",
      " -0.06133516 -0.06953748 -0.04075741 -0.05622305  0.0595966   0.03533198\n",
      " -0.08887114 -0.36518136 -0.0894075  -0.1084986   0.18221459 -0.08119096\n",
      " -0.03991854  0.04265938 -0.19503699 -0.13011599 -0.04484828  0.03442392\n",
      "  0.04920021 -0.03798074  0.18616784 -0.10357659 -0.16796622 -0.09509327\n",
      " -0.00634333  0.2222579   0.23889761  0.01217391  0.0124667  -0.03526229\n",
      "  0.08327612 -0.18970941  0.0235301   0.1457344   0.15535954 -0.04044572\n",
      "  0.008743   -0.12969546 -0.07063119  0.07693525 -0.19312617  0.01102489\n",
      "  0.05665991 -0.0886092  -0.10907459 -0.07560083  0.1981283   0.11303246\n",
      " -0.07860767 -0.19330999  0.23112272 -0.15245375  0.03162218  0.13459234\n",
      " -0.11380838 -0.08609732 -0.2911666   0.01566404  0.38064229  0.05104271\n",
      " -0.15700263 -0.0293577  -0.16685335 -0.00755922 -0.05636193 -0.00147579\n",
      " -0.13538843 -0.02588619 -0.1585833  -0.00632158  0.1213316  -0.00875412\n",
      " -0.01722242  0.16935976  0.00180238  0.01982424  0.04959955  0.0739164\n",
      " -0.06845086 -0.0124468  -0.08638898 -0.00732337  0.09521808 -0.09273262\n",
      "  0.02474161  0.11897486 -0.1584812   0.11264024 -0.01271113  0.04810141\n",
      "  0.04419734 -0.04122462 -0.02218474 -0.0849052   0.19598031 -0.23152867\n",
      "  0.11648317  0.16081168 -0.01341658  0.12596467  0.02686257  0.09283239\n",
      " -0.05622514 -0.02372829 -0.10101162 -0.06804189 -0.0006483  -0.1277391\n",
      "  0.03177035  0.04679968]\n",
      " Encodings of Face... 2\n",
      "[-0.22193065  0.12499592  0.10038    -0.02542698  0.00989413 -0.12114065\n",
      "  0.06567045 -0.13937058  0.14593059 -0.07303145  0.17244032  0.00694975\n",
      " -0.14361943 -0.12224553  0.05009896  0.08734572 -0.20581147 -0.11959291\n",
      " -0.03124781 -0.13018976  0.00631646  0.03279769  0.02694338  0.04754643\n",
      " -0.10153037 -0.29550779 -0.12888505 -0.16213775  0.1087574  -0.02209755\n",
      "  0.05195981 -0.01744253 -0.16712371 -0.02877522 -0.0387881   0.01292452\n",
      "  0.02674198 -0.06954889  0.17105901  0.07384919 -0.07904606 -0.06287206\n",
      " -0.02469539  0.27091333  0.12724335 -0.03037122  0.02193146 -0.01263473\n",
      "  0.12264305 -0.13680115 -0.00862042  0.10755638  0.17736147  0.05262891\n",
      "  0.01402998 -0.15078235  0.06202216 -0.00654537 -0.21125357  0.04765409\n",
      "  0.07421333 -0.08798516 -0.09030055  0.03266014  0.2495622   0.10298094\n",
      " -0.07350756 -0.14619325  0.24381983 -0.10024598 -0.00403399  0.02841915\n",
      " -0.11967283 -0.07990871 -0.14535935  0.1062157   0.2862955   0.08561833\n",
      " -0.13511282  0.0059926  -0.27058128  0.03607268 -0.05941473  0.03491274\n",
      " -0.13808972 -0.00275417 -0.08886126 -0.02538459  0.10622334  0.00460067\n",
      " -0.01936112  0.21056646  0.01387949  0.02676885  0.01572283 -0.11186784\n",
      " -0.11453885  0.03439361 -0.00185782 -0.02276801  0.08152258 -0.14543635\n",
      "  0.04113464  0.12688364 -0.25679308  0.18276942  0.02082638 -0.00642245\n",
      "  0.04789361  0.06387225 -0.09942655 -0.06180105  0.12140997 -0.21310335\n",
      "  0.23004231  0.19636387  0.03301858  0.15293007  0.01424526  0.09723444\n",
      " -0.04930063  0.0303874  -0.11336164 -0.03028634  0.05160528 -0.07221282\n",
      " -0.06581521  0.04814454]\n",
      " Encodings of Face... 3\n",
      "[-1.13188937e-01  1.04338430e-01  1.50961474e-01 -4.25322130e-02\n",
      " -5.01203947e-02 -1.17267296e-01 -1.54246241e-02 -1.66362733e-01\n",
      "  9.44492146e-02 -9.40680802e-02  2.97975004e-01 -8.07714760e-02\n",
      " -1.36008680e-01 -1.70830458e-01  1.05151851e-02  1.56764090e-01\n",
      " -1.72224060e-01 -1.39577493e-01 -2.88800187e-02 -7.43880048e-02\n",
      " -3.47981229e-04 -1.97634683e-03  5.63430004e-02  6.99293986e-02\n",
      " -6.81154951e-02 -3.10804904e-01 -1.37475356e-01 -1.33980364e-01\n",
      "  8.15229788e-02 -2.35476252e-02 -1.95458122e-02  1.27360493e-01\n",
      " -2.01066390e-01 -1.63989719e-02  2.31382437e-02  1.06469737e-02\n",
      "  3.95561382e-02 -3.74821164e-02  1.83453336e-01  1.98067073e-03\n",
      " -1.65058807e-01 -3.80016901e-02  5.25970152e-03  1.94332138e-01\n",
      "  2.21506774e-01 -4.11406048e-02  2.91238166e-03 -6.24293685e-02\n",
      "  6.35532588e-02 -1.51347563e-01  2.08498277e-02  1.75027683e-01\n",
      "  1.38524339e-01  3.89713980e-02 -3.10682580e-02 -9.61048454e-02\n",
      " -4.87033743e-03  9.01384652e-02 -1.94630295e-01 -2.09706314e-02\n",
      "  1.55599946e-02 -1.33919984e-01 -1.22518487e-01 -2.38591079e-02\n",
      "  2.33611241e-01  1.57998443e-01 -1.04353316e-01 -1.68035612e-01\n",
      "  2.44428053e-01 -1.21785514e-01 -1.92184038e-02  1.27986208e-01\n",
      " -1.70650288e-01 -9.44524705e-02 -1.86437890e-01  2.73054242e-02\n",
      "  3.55817884e-01  2.84015629e-02 -2.43525580e-01  2.87477346e-03\n",
      " -2.05668464e-01 -2.79397401e-03 -1.56180598e-02  7.98186585e-02\n",
      " -5.25483415e-02 -3.69007662e-02 -6.27395213e-02 -4.10566032e-02\n",
      "  1.54769212e-01 -5.71041778e-02 -5.43404743e-03  2.43137062e-01\n",
      " -5.44772204e-03  1.84558053e-02  4.16229069e-02 -5.08615524e-02\n",
      "  2.68315189e-02 -5.49353175e-02 -1.06158219e-01 -7.38860667e-02\n",
      " -4.25029173e-02 -7.72832185e-02 -9.55796391e-02  9.20613110e-02\n",
      " -2.35988617e-01  1.26706183e-01  4.58370782e-02 -2.83434037e-02\n",
      "  1.00016184e-02 -4.39448729e-02  6.90672174e-03 -8.22563842e-02\n",
      "  1.40174598e-01 -2.38797307e-01  1.87182471e-01  1.58786699e-01\n",
      "  3.59471031e-02  1.49219424e-01 -4.47095651e-03  1.16112687e-01\n",
      " -4.10598665e-02 -1.35635838e-01 -8.55305865e-02 -3.18165608e-02\n",
      "  1.17742948e-01 -6.86122030e-02 -4.03410532e-02 -3.32164839e-02]\n",
      " Encodings of Face... 4\n",
      "[-1.65492952e-01  8.61738622e-02  9.33240578e-02 -6.96392581e-02\n",
      " -1.15186773e-01  5.85452141e-03 -1.17043043e-02 -1.05596930e-01\n",
      "  1.48125783e-01 -5.05127311e-02  1.53127462e-01  4.32962142e-02\n",
      " -2.21466467e-01 -9.32221860e-02  1.22062722e-02  1.14956342e-01\n",
      " -1.50076002e-01 -2.36689329e-01 -6.60464987e-02 -3.60155925e-02\n",
      " -4.14004456e-03  5.04827537e-02 -2.64471229e-02  2.44641639e-02\n",
      " -1.69514865e-01 -3.45610380e-01 -2.17415746e-02 -9.46988389e-02\n",
      " -3.95579543e-03 -9.27874520e-02 -6.02227896e-02  5.43845817e-02\n",
      " -2.27533177e-01 -6.87598512e-02  2.93550007e-02  1.12898566e-01\n",
      " -5.89440428e-02 -8.88904408e-02  1.87896356e-01  5.92915341e-02\n",
      " -2.20114052e-01 -1.76918432e-02  5.98950870e-02  2.98328042e-01\n",
      "  2.27774203e-01 -1.66160408e-02  5.65996096e-02 -5.89459091e-02\n",
      "  1.48864746e-01 -3.45190972e-01  7.03827441e-02  1.65874064e-01\n",
      "  6.83778077e-02  4.77973893e-02  6.45461455e-02 -1.99059263e-01\n",
      " -6.90634642e-03  9.10926312e-02 -1.87473774e-01  1.35623246e-01\n",
      "  6.79997802e-02 -9.47994813e-02 -7.85425901e-02 -4.79136258e-02\n",
      "  1.94389939e-01  1.46187574e-01 -5.10571152e-02 -1.93863899e-01\n",
      "  2.22639903e-01 -1.56261802e-01 -9.42333490e-02  8.40587839e-02\n",
      " -1.04173228e-01 -1.88886479e-01 -2.43475944e-01  2.85615716e-02\n",
      "  3.02600294e-01  1.27767235e-01 -2.14048013e-01  1.42896604e-02\n",
      " -1.17989391e-01  3.45978215e-02  6.02059476e-02  3.50816101e-02\n",
      " -2.76335534e-02  1.46105355e-02 -1.31907776e-01 -8.74944869e-03\n",
      "  3.17642152e-01  2.29800679e-02 -8.99052434e-03  2.53887385e-01\n",
      "  6.07713461e-02 -6.82397932e-02  1.01904675e-01  6.77592009e-02\n",
      " -6.58302158e-02 -1.30007658e-02 -2.01405421e-01 -5.96630126e-02\n",
      "  9.25578251e-02 -1.12057932e-01  3.07673006e-03  1.67918980e-01\n",
      " -2.41325170e-01  1.51224867e-01 -3.34526822e-02 -8.20735097e-03\n",
      "  5.16075082e-03 -9.11682993e-02 -7.89218992e-02 -3.15883979e-02\n",
      "  1.65628836e-01 -2.15710968e-01  2.34801680e-01  2.04967305e-01\n",
      "  3.79437543e-02  1.24861650e-01  4.37874384e-02  1.33115901e-02\n",
      " -1.63977966e-05 -4.52064015e-02 -1.53961435e-01 -9.70249102e-02\n",
      "  3.46262455e-02 -1.81367770e-02 -2.55030673e-02  6.84777349e-02]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "photo_gr = face_recognition.load_image_file('./pics&group/group1.jpeg','RGB')\n",
    "encodings_gr = face_recognition.face_encodings(photo_gr)\n",
    "print(\"The Number of faces  ...\", len(encodings_gr))\n",
    "print(\"The shape of each encodings..\", encodings_gr[0].shape)\n",
    "print(\"Now let us print the encoding\")\n",
    "for i in range(len(encodings_gr)):\n",
    "    print(\" Encodings of Face...\", i)\n",
    "    print(encodings_gr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314b106",
   "metadata": {},
   "source": [
    "## Distance Function and Resemblance of Faces\n",
    "\n",
    "The purpose of encoding is to find a unique signature for a face. If we consider two face photos of the same person and find out the encodings of each photo. The two encodings are almost same. This means that the Euclidean distance between them is as small as less than 0.6. If the two encodings are for two different person's photos, the distance is more than 0.6. \n",
    "People with resemblance have encodings with distances small and people with totally difference face appearances have encodings of distance high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e59c69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between the two photos  [0.40638764]\n"
     ]
    }
   ],
   "source": [
    "#Program to find distance between faces\n",
    "import face_recognition\n",
    "photo_recog1 = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "encodings_recog1 = face_recognition.face_encodings(photo_recog1)[0]\n",
    "\n",
    "photo_recog2 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "encodings_recog2 = face_recognition.face_encodings(photo_recog2)[0]\n",
    "dist = face_recognition.face_distance([encodings_recog1],encodings_recog2)\n",
    "print(\"Distance between the two photos \", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642e79f",
   "metadata": {},
   "source": [
    "## Distance between multiple photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43de01c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: pic1 to pic2, pic3, pic4,  and pic5 respectively\n",
      "[0.40638764 0.38324746 0.32724422 0.41067434]\n"
     ]
    }
   ],
   "source": [
    "#Program to load a picture and find its face encoding of same person\n",
    "import face_recognition\n",
    "fa = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "f0 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "f1 = face_recognition.load_image_file('./pics&group/pic3.jpeg','RGB')\n",
    "f2 = face_recognition.load_image_file('./pics&group/pic4.jpeg','RGB')\n",
    "f3 = face_recognition.load_image_file('./pics&group/pic5.jpeg','RGB')\n",
    "\n",
    "fa_sign = face_recognition.face_encodings(fa)[0]\n",
    "f0_sign = face_recognition.face_encodings(f0)[0]\n",
    "f1_sign = face_recognition.face_encodings(f1)[0]\n",
    "f2_sign = face_recognition.face_encodings(f2)[0]\n",
    "f3_sign = face_recognition.face_encodings(f3)[0]\n",
    "\n",
    "\n",
    "faces = [f0_sign, f1_sign, f2_sign, f3_sign ]\n",
    "dist = face_recognition.face_distance(faces,fa_sign)\n",
    "print(\"Distance: pic1 to pic2, pic3, pic4,  and pic5 respectively\")\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bed73a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance 1 to 2  [0.6686964]\n",
      "Distance 2 to 3  [0.71448367]\n",
      "Distance 3 to 4  [0.78403007]\n",
      "Distance 4 to 5  [0.89384318]\n",
      "Distance 5 to 1  [0.89317529]\n"
     ]
    }
   ],
   "source": [
    "#Program to load five photos of different person\n",
    "import face_recognition\n",
    "#Load the five photos of the different person\n",
    "celebrit1 = face_recognition.load_image_file('./face_recog/celebrit1.jpg','RGB')\n",
    "celebrit2 = face_recognition.load_image_file('./face_recog/celebrit2.jpg','RGB')\n",
    "celebrit3 = face_recognition.load_image_file('./face_recog/celebrit3.jpg','RGB')\n",
    "celebrit4 = face_recognition.load_image_file('./face_recog/celebrit4.jpg','RGB')\n",
    "celebrit5 = face_recognition.load_image_file('./face_recog/celebrit5.jpg','RGB')\n",
    "\n",
    "#Let us find the encodings for each of the five faces\n",
    "encodings_celebrit1 = face_recognition.face_encodings(celebrit1)[0]\n",
    "encodings_celebrit2 = face_recognition.face_encodings(celebrit2)[0]\n",
    "encodings_celebrit3 = face_recognition.face_encodings(celebrit3)[0]\n",
    "encodings_celebrit4 = face_recognition.face_encodings(celebrit4)[0]\n",
    "encodings_celebrit5 = face_recognition.face_encodings(celebrit5)[0]\n",
    "\n",
    "# Let us find the distances between faces\n",
    "dist01_02 = face_recognition.face_distance([encodings_celebrit1],encodings_celebrit2)\n",
    "dist02_03 = face_recognition.face_distance([encodings_celebrit2],encodings_celebrit3)\n",
    "dist03_04 = face_recognition.face_distance([encodings_celebrit3],encodings_celebrit4)\n",
    "dist04_05 = face_recognition.face_distance([encodings_celebrit4],encodings_celebrit5)\n",
    "dist05_01 = face_recognition.face_distance([encodings_celebrit5],encodings_celebrit1)\n",
    "print(\"Distance 1 to 2 \", dist01_02)\n",
    "print(\"Distance 2 to 3 \", dist02_03)\n",
    "print(\"Distance 3 to 4 \", dist03_04)\n",
    "print(\"Distance 4 to 5 \", dist04_05)\n",
    "print(\"Distance 5 to 1 \", dist05_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69b5af",
   "metadata": {},
   "source": [
    "## Face mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19f338e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance: Son 0 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.72990638 0.79360617 0.74602903 0.70046816 0.83568435 0.93820042]\n",
      "\n",
      "Distance: Son 1 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.68449085 0.67372911 0.7230144  0.66845835 0.7651907  0.82157798]\n",
      "\n",
      "Distance: Son 2 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.84429839 0.7744297  0.71290187 0.80236541 0.78670347 0.88211748]\n",
      "\n",
      "Distance: Son 3 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.77117768 0.81288294 0.77629569 0.68695563 0.84930817 0.98030858]\n",
      "\n",
      "Distance: Son 4 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.77196765 0.80404854 0.86240018 0.87669905 0.64447716 0.77138433]\n",
      "\n",
      "Distance: Son 5 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.84356954 0.83386023 0.83312569 0.81627252 0.80699236 0.73860243]\n"
     ]
    }
   ],
   "source": [
    "#Father to Son face mapping\n",
    "# Python program to recognize the photo of a son and map to\n",
    "# the father depending upon the resemblance.\n",
    "\n",
    "import face_recognition\n",
    "n = 6\n",
    "photo_father =[]\n",
    "encodings_father = []\n",
    "photo_son = []\n",
    "encodings_son = []\n",
    "for i in range(n):\n",
    "    f_path_template = './father/father0{}.png'\n",
    "    f_path = f_path_template.format(i)\n",
    "    photo_father.append(face_recognition.load_image_file(f_path,'RGB'))\n",
    "    encodings_father.append(face_recognition.face_encodings(photo_father[i])[0])\n",
    "    \n",
    "    s_path_template = './son/son0{}.png'\n",
    "    s_path = s_path_template.format(i)\n",
    "    photo_son.append(face_recognition.load_image_file(s_path,'RGB'))\n",
    "    encodings_son.append(face_recognition.face_encodings(photo_son[i])[0])\n",
    "    \n",
    "for i in range(6):\n",
    "    a = \"\\nDistance: Son {} to Fathers 0, 1, 2, 3, 4, 5\"\n",
    "    print(a.format(i))\n",
    "    print(face_recognition.face_distance(encodings_father, encodings_son[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187cdbc",
   "metadata": {},
   "source": [
    "## Face Recognition – Compare method\n",
    "\n",
    "In this method, compare_ faces() is used to\n",
    "compare faces and recognize the faces.\n",
    "\n",
    "The input parameters are:\n",
    "1. A list of known face encodings\n",
    "2. One unknown face encoding\n",
    "The unknown face is compared with each of the known face fi in the List and a\n",
    "Boolean value found(i) is created whether they match or not. The Boolean list found is\n",
    "returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d758dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Emmanuel \n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "image_emman = face_recognition.load_image_file('./pics&group/pic1.jpeg')\n",
    "emman_encod = face_recognition.face_encodings(image_emman)[0]\n",
    "\n",
    "image_em = face_recognition.load_image_file('./pics&group/pic5.jpeg')\n",
    "em_encod = face_recognition.face_encodings(image_em)[0]\n",
    "results = face_recognition.compare_faces([emman_encod], em_encod, tolerance = 0.5)\n",
    "if results[0]:\n",
    "    print(\"This is Emmanuel \")\n",
    "else:\n",
    "    print('This is NOT Emmanuel ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "005e99cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is NOT Emmanuel \n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "image_emman = face_recognition.load_image_file('./pics&group/pic1.jpeg')\n",
    "emman_encod = face_recognition.face_encodings(image_emman)[0]\n",
    "\n",
    "image_em = face_recognition.load_image_file('./pics&group/pic6.jpeg')\n",
    "em_encod = face_recognition.face_encodings(image_em)[0]\n",
    "results = face_recognition.compare_faces([emman_encod], em_encod, tolerance = 0.5)\n",
    "if results[0]:\n",
    "    print(\"This is Emmanuel \")\n",
    "else:\n",
    "    print('This is NOT Emmanuel ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535750c5",
   "metadata": {},
   "source": [
    "## Face compare among unknown pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2cb34ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "pict_1 = face_recognition.load_image_file('./face_recog/celebrit1.jpg','RGB')\n",
    "pict_2 = face_recognition.load_image_file('./face_recog/celebrit2.jpg','RGB')\n",
    "pict_3 = face_recognition.load_image_file('./face_recog/celebrit3.jpg','RGB')\n",
    "pict_4 = face_recognition.load_image_file('./face_recog/celebrit4.jpg','RGB')\n",
    "pict_5 = face_recognition.load_image_file('./face_recog/celebrit5.jpg','RGB')\n",
    "pict_6 = face_recognition.load_image_file('./face_recog/pic3.jpeg','RGB')\n",
    "pict_unkwn = face_recognition.load_image_file('./pics&group/unknown.jpeg','RGB')\n",
    "\n",
    "pict_unkwn_sign = face_recognition.face_encodings(pict_unkwn)[0]\n",
    "pict1_sign = face_recognition.face_encodings(pict_1)[0]\n",
    "pict2_sign = face_recognition.face_encodings(pict_2)[0]\n",
    "pict3_sign = face_recognition.face_encodings(pict_3)[0]\n",
    "pict4_sign = face_recognition.face_encodings(pict_4)[0]\n",
    "pict5_sign = face_recognition.face_encodings(pict_5)[0]\n",
    "pict6_sign = face_recognition.face_encodings(pict_6)[0]\n",
    "\n",
    "faces = [pict1_sign, pict2_sign, pict3_sign, pict4_sign, pict5_sign, pict6_sign ]\n",
    "\n",
    "compare_fnd = face_recognition.compare_faces(faces,pict_unkwn_sign, tolerance = 0.4)\n",
    "\n",
    "print(\"Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\")\n",
    "print(compare_fnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4df0a91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\n",
      "[False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "pict_1 = face_recognition.load_image_file('./face_recog/celebrit1.jpg','RGB')\n",
    "pict_2 = face_recognition.load_image_file('./face_recog/celebrit2.jpg','RGB')\n",
    "pict_3 = face_recognition.load_image_file('./face_recog/celebrit3.jpg','RGB')\n",
    "pict_4 = face_recognition.load_image_file('./face_recog/celebrit4.jpg','RGB')\n",
    "pict_5 = face_recognition.load_image_file('./face_recog/celebrit5.jpg','RGB')\n",
    "pict_6 = face_recognition.load_image_file('./face_recog/pic3.jpeg','RGB')\n",
    "pict_unkwn = face_recognition.load_image_file('./pics&group/pic6.jpeg','RGB')\n",
    "\n",
    "pict_unkwn_sign = face_recognition.face_encodings(pict_unkwn)[0]\n",
    "pict1_sign = face_recognition.face_encodings(pict_1)[0]\n",
    "pict2_sign = face_recognition.face_encodings(pict_2)[0]\n",
    "pict3_sign = face_recognition.face_encodings(pict_3)[0]\n",
    "pict4_sign = face_recognition.face_encodings(pict_4)[0]\n",
    "pict5_sign = face_recognition.face_encodings(pict_5)[0]\n",
    "pict6_sign = face_recognition.face_encodings(pict_6)[0]\n",
    "\n",
    "faces = [pict1_sign, pict2_sign, pict3_sign, pict4_sign, pict5_sign, pict6_sign ]\n",
    "\n",
    "compare_fnd = face_recognition.compare_faces(faces,pict_unkwn_sign, tolerance = 0.4)\n",
    "\n",
    "print(\"Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\")\n",
    "print(compare_fnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e857880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\n",
      "[True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "pict_1 = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "pict_2 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "pict_3 = face_recognition.load_image_file('./pics&group/pic3.jpeg','RGB')\n",
    "pict_4 = face_recognition.load_image_file('./pics&group/pic4.jpeg','RGB')\n",
    "pict_5 = face_recognition.load_image_file('./pics&group/pic5.jpeg','RGB')\n",
    "pict_6 = face_recognition.load_image_file('./pics&group/pic6.jpeg','RGB')\n",
    "pict_unkwn = face_recognition.load_image_file('./pics&group/unknown.jpeg','RGB')\n",
    "\n",
    "pict_unkwn_sign = face_recognition.face_encodings(pict_unkwn)[0]\n",
    "pict1_sign = face_recognition.face_encodings(pict_1)[0]\n",
    "pict2_sign = face_recognition.face_encodings(pict_2)[0]\n",
    "pict3_sign = face_recognition.face_encodings(pict_3)[0]\n",
    "pict4_sign = face_recognition.face_encodings(pict_4)[0]\n",
    "pict5_sign = face_recognition.face_encodings(pict_5)[0]\n",
    "pict6_sign = face_recognition.face_encodings(pict_6)[0]\n",
    "\n",
    "faces = [pict1_sign, pict2_sign, pict3_sign, pict4_sign, pict5_sign, pict6_sign ]\n",
    "\n",
    "compare_fnd = face_recognition.compare_faces(faces,pict_unkwn_sign, tolerance = 0.4)\n",
    "\n",
    "print(\"Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\")\n",
    "print(compare_fnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975acfb",
   "metadata": {},
   "source": [
    "## Image Data storage and compare using Python Pandas CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20d1f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Staff_ID         Name                   File Name\n",
      "0       201   Image_Pic1  ./face_recog/celebrit1.jpg\n",
      "1       202   Image_Pic2  ./face_recog/celebrit2.jpg\n",
      "2       203   Image_Pic3  ./face_recog/celebrit3.jpg\n",
      "3       204   Image_Pic4  ./face_recog/celebrit4.jpg\n",
      "4       205   Image_Pic5  ./face_recog/celebrit5.jpg\n",
      "5       206  Immage_Pic6      ./face_recog/pic3.jpeg\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import face_recognition\n",
    "f = pd.read_csv('./Data.csv')\n",
    "print(f.to_string())\n",
    "empno = f[\"Staff_ID\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "ukwn= face_recognition.load_image_file(\"./pics&group/pic1.jpeg\")\n",
    "ukwn_encod = face_recognition.face_encodings(ukwn)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "found = face_recognition.compare_faces(emp_encod, ukwn_encod, tolerance = 0.5)    \n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b233f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Staff_ID        Name                   File Name\n",
      "0       201  Image_Pic1  ./face_recog/celebrit1.jpg\n",
      "1       202  Image_Pic2  ./face_recog/celebrit2.jpg\n",
      "2       203  Image_Pic3  ./face_recog/celebrit3.jpg\n",
      "3       204  Image_Pic4  ./face_recog/celebrit4.jpg\n",
      "4       205  Image_Pic5  ./face_recog/celebrit5.jpg\n",
      "5       206  Image_Pic6      ./face_recog/pic3.jpeg\n",
      "(1024, 769, 3)\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "fnt = ImageFont.truetype(\"calibri.ttf\", 60, encoding=\"unic\")\n",
    "\n",
    "f = pd.read_csv('./Data.csv')\n",
    "\n",
    "print(f.to_string())\n",
    "empno = f[\"Staff_ID\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "ukwn= face_recognition.load_image_file(\"./pics&group/pic1.jpeg\")\n",
    "print(ukwn.shape)\n",
    "ukwn_encod = face_recognition.face_encodings(ukwn)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "    \n",
    "found = face_recognition.compare_faces(emp_encod,ukwn_encod, tolerance = 0.4)    \n",
    "print(found)\n",
    "for i in range(n):\n",
    "    if found[i]:\n",
    "    \n",
    "        left = 100\n",
    "        bottom = ukwn.shape[0]\n",
    "        pil_ukwn = Image.fromarray(ukwn)\n",
    "        draw = ImageDraw.Draw(pil_ukwn)\n",
    "        draw.text((left,bottom - 250), name[i], font=fnt, fill=(255,0,0))\n",
    "        pil_ukwn.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b68653",
   "metadata": {},
   "source": [
    "## Attendance Recording in a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "995df71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Staff_ID        Name                   File Name\n",
      "0       201  Image_Pic1  ./face_recog/celebrit1.jpg\n",
      "1       202  Image_Pic2  ./face_recog/celebrit2.jpg\n",
      "2       203  Image_Pic3  ./face_recog/celebrit3.jpg\n",
      "3       204  Image_Pic4  ./face_recog/celebrit4.jpg\n",
      "4       205  Image_Pic5  ./face_recog/celebrit5.jpg\n",
      "5       206  Image_Pic6      ./face_recog/pic3.jpeg\n",
      "(1024, 1019, 3)\n",
      "[False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import face_recognition\n",
    "f = pd.read_csv('./Data.csv')\n",
    "print(f.to_string())\n",
    "empno = f[\"Staff_ID\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "ukwn= face_recognition.load_image_file(\"./pics&group/pic6.jpeg\")\n",
    "print(ukwn.shape)\n",
    "ukwn_encod = face_recognition.face_encodings(ukwn)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "    \n",
    "found = face_recognition.compare_faces(emp_encod,ukwn_encod, tolerance = 0.4)    \n",
    "print(found)\n",
    "for i in range(n):\n",
    "    if found[i]:\n",
    "        x = str(datetime.datetime.now())\n",
    "        attend = \"\\n\"+str(empno[i])+' '+str(name[i]+' '+x)\n",
    "        f = open(\"Attendance.txt\", \"a\")\n",
    "        f.write(attend)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3add54fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    print(return_value, image.shape)\n",
    "    cv2.imwrite('photo'+str(i)+'.png', image)\n",
    "del(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9d69542",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6628/3668204409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# Module 1 Reference Data Load Module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./database/staff_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygame'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./database/staff_data.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f789ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308777a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501857d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42823873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
