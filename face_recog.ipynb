{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b3ed0d",
   "metadata": {},
   "source": [
    "## Face Recognition\n",
    "Face recognition is a branch of Artificial Intelligence technology which deals about detecting a human face in an image, recognize the identity, gender, age and more attributes of the person and even the emotions.\n",
    "Face recognition is one of the high-level intellectual capability of human beings\n",
    "\n",
    "## Face Recognition Approaches\n",
    "Broadly there are three sets of scientists working on face recognition and\n",
    "related fields. They are\n",
    "1. Medical Scientists – Cognitive strategies\n",
    "2. Anthropological Researchers\n",
    "3. Artificial Intelligence Researchers using Computer Vision with Deep Learning [Convolution Neutral Networks].\n",
    "\n",
    "In Artificial Intelligence research the image of the face is represented as a matrix of pixels. By analyzing the image, we try to find the unique set of numbers, called a signature. We use face signature for face recognition. Each image is  considered as a matrix of pixels. Each pixel is represented by a set of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fd9f3",
   "metadata": {},
   "source": [
    "## Python face-recognition Library\n",
    "\n",
    "Python face-recognition library is a simple, user-friendly library with methods useful for to recognize and manipulate faces from Python\n",
    "\n",
    "## Python library Face-recognition is built on three important foundations.\n",
    "1. CMake\n",
    "2. Dlib\n",
    "3. Open CV\n",
    "\n",
    "CMake: CMake is a cross-platform free an open source software tool. This is used to manage the software building process using compiler independent method.\n",
    "\n",
    "Dlib: is a dynamic library. This is actually a modem C++ to solve real life problem. This contains machine learning algorithms and tools for building complex software in C++ to solve real life problem. Most of the Machine Learning packages are built on Dlib\n",
    "\n",
    "Open CV (opensource computer vision) This is a very popular opensource library implementing Computer Vision algorithms using Machine Learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930960fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the Color photo files are...\n",
      "photo1 Photo.... (1024, 769, 3)\n",
      "photo2 Photo..... (1024, 769, 3)\n",
      "photo3 Photo...... (1024, 769, 3)\n"
     ]
    }
   ],
   "source": [
    "#loading of images and check for the image shape\n",
    "\n",
    "import face_recognition\n",
    "photo1 = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "photo2 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "photo3 = face_recognition.load_image_file('./pics&group/pic3.jpeg')\n",
    "print(\"The shapes of the Color photo files are...\")\n",
    "print(\"photo1 Photo....\",photo1.shape)\n",
    "print(\"photo2 Photo.....\", photo2.shape)\n",
    "print(\"photo3 Photo......\", photo3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7ad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the bw photo files are...\n",
      "photoA Photo.... (1024, 769)\n",
      "photoB Photo..... (1024, 769)\n",
      "photoC Photo...... (1024, 769)\n"
     ]
    }
   ],
   "source": [
    "# we want to load the files in Black and White format we must use using 'L'\n",
    "# attribute in the second attribute of load_image_file() function as follows:\n",
    "\n",
    "photoA = face_recognition.load_image_file('./pics&group/pic1.jpeg','L')\n",
    "photoB = face_recognition.load_image_file('./pics&group/pic2.jpeg','L')\n",
    "photoC = face_recognition.load_image_file('./pics&group/pic3.jpeg', 'L')\n",
    "print(\"The shapes of the bw photo files are...\")\n",
    "print(\"photoA Photo....\",photoA.shape)\n",
    "print(\"photoB Photo.....\", photoB.shape)\n",
    "print(\"photoC Photo......\", photoC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf1403",
   "metadata": {},
   "source": [
    "## Python Image Library\n",
    "\n",
    "Python Image Library (PIL) is a opensource library for Python that supports image processing\n",
    "activities of pictures, including the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c525a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "pil_image1 = Image.fromarray(photo1)\n",
    "pil_image1.show()\n",
    "pil_image2 = Image.fromarray(photo2)\n",
    "pil_image2.show()\n",
    "pil_image3 = Image.fromarray(photo3)\n",
    "pil_image3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb131fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image1 = Image.fromarray(photoA)\n",
    "pil_image1.show()\n",
    "pil_image2 = Image.fromarray(photoB)\n",
    "pil_image2.show()\n",
    "pil_image3 = Image.fromarray(photoC)\n",
    "pil_image3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73655de2",
   "metadata": {},
   "source": [
    "## Face Locations Method\n",
    "\n",
    "In python face-recognition library, face_locations() method detects all human faces in the image.\n",
    "Each face is detected as a rectangular frame in the form of a tuple (top,left,bottom,right). If there are n faces, the output is a list of n tuples with four entries as (top, right, bottom, left)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8720e2a",
   "metadata": {},
   "source": [
    "## HOG (Histogram Oriented Gradient) Approach.\n",
    "\n",
    "In detecting the faces and locating the rectangular frames HOG (Histogram Oriented Gradient) Approach. This is faster but less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af17e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(376, 546, 761, 161), (580, 184, 735, 29)]\n",
      "(1024, 769, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "test_pic3 = face_recognition.load_image_file('./pics&group/pic3.jpeg')\n",
    "print(test_pic3.shape)\n",
    "l = face_recognition.face_locations(test_pic3, model = 'hog')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "pic3_face = test_pic3[top:bottom, left:right]\n",
    "print(test_pic3.shape)\n",
    "pic3_face_image = Image.fromarray(pic3_face)\n",
    "pic3_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef633f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  8 face(s) in this photo\n",
      "Face 1...Top: 132, Left: 117, Bottom: 175, Right: 160\n",
      "Face 2...Top: 137, Left: 36, Bottom: 180, Right: 79\n",
      "Face 3...Top: 159, Left: 273, Bottom: 211, Right: 325\n",
      "Face 4...Top: 103, Left: 213, Bottom: 146, Right: 256\n",
      "Face 5...Top: 136, Left: 406, Bottom: 188, Right: 458\n",
      "Face 6...Top: 134, Left: 357, Bottom: 170, Right: 393\n",
      "Face 7...Top: 142, Left: 568, Bottom: 185, Right: 612\n",
      "Face 8...Top: 153, Left: 717, Bottom: 205, Right: 769\n"
     ]
    }
   ],
   "source": [
    "#Face Detection using HOG Model \n",
    "\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"hog\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b6145",
   "metadata": {},
   "source": [
    "## Deep Learning based Convolution Neural Network (CNN) Approach.\n",
    "\n",
    "CNN is more accurate but it takes more time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1193ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(386, 506, 739, 154), (560, 196, 729, 26)]\n",
      "(353, 352, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "test2_photo = face_recognition.load_image_file('./pics&group/pic3.jpeg')\n",
    "print(test2_photo.shape)\n",
    "l = face_recognition.face_locations(test2_photo, model ='cnn')\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "test2_image = test2_photo[top:bottom, left:right]\n",
    "print(test2_image.shape)\n",
    "test2_face_image = Image.fromarray(test2_image)\n",
    "test2_face_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a22ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  10 face(s) in this photo\n",
      "Face 1...Top: 153, Left: 275, Bottom: 201, Right: 322\n",
      "Face 2...Top: 133, Left: 37, Bottom: 173, Right: 76\n",
      "Face 3...Top: 139, Left: 409, Bottom: 186, Right: 456\n",
      "Face 4...Top: 139, Left: 567, Bottom: 186, Right: 615\n",
      "Face 5...Top: 144, Left: 174, Bottom: 191, Right: 221\n",
      "Face 6...Top: 158, Left: 726, Bottom: 206, Right: 773\n",
      "Face 7...Top: 133, Left: 117, Bottom: 173, Right: 156\n",
      "Face 8...Top: 96, Left: 207, Bottom: 143, Right: 255\n",
      "Face 9...Top: 133, Left: 353, Bottom: 173, Right: 392\n",
      "Face 10...Top: 165, Left: 685, Bottom: 205, Right: 724\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning based Convolution Neural Network (CNN) approach. CNN\n",
    "# is more accurate but it takes more time to compute.\n",
    "\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"cnn\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d43da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2 face(s) in this photo\n",
      "Face 1...Top: 386, Left: 154, Bottom: 739, Right: 506\n",
      "Face 2...Top: 560, Left: 26, Bottom: 729, Right: 196\n"
     ]
    }
   ],
   "source": [
    "group_photo = face_recognition.load_image_file(\"./pics&group/pic3.jpeg\")\n",
    "\n",
    "# Find all the faces in the image \n",
    "face_locations = face_recognition.face_locations(group_photo, model=\"cnn\")\n",
    "# Let us print the number of faces in the Photo\n",
    "print(\"There are  {} face(s) in this photo\".format(len(face_locations)))\n",
    "face_count = 0\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image\n",
    "    face_count = face_count+1\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"Face {}...Top: {}, Left: {}, Bottom: {}, Right: {}\".format(face_count,top, left, bottom, right))\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = group_photo[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24b176",
   "metadata": {},
   "source": [
    " ## Locate Faces and Mark with rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a559ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(333, 675, 718, 290)]\n",
      "(385, 385, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "test_photo = face_recognition.load_image_file('./pics&group/pic5.jpeg')\n",
    "print(test_photo.shape)\n",
    "l = face_recognition.face_locations(test_photo)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "test_face = test_photo[top:bottom, left:right]\n",
    "print(test_face.shape)\n",
    "test_face_image = Image.fromarray(test_face)\n",
    "#text_face_image.show()\n",
    "test_photo_image = Image.fromarray(test_photo)\n",
    "draw = ImageDraw.Draw(test_photo_image)\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline = (0, 0, 255), width = 5)\n",
    "test_photo_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbddd9",
   "metadata": {},
   "source": [
    "## Writing text on a Face Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5b1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 769, 3)\n",
      "[(333, 675, 718, 290)]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "photo_text = face_recognition.load_image_file('./pics&group/pic5.jpeg')\n",
    "print(photo_text.shape)\n",
    "l = face_recognition.face_locations(photo_text)\n",
    "print(l)\n",
    "top = l[0][0]\n",
    "right = l[0][1]\n",
    "bottom = l[0][2]\n",
    "left = l[0][3]\n",
    "\n",
    "\n",
    "#text_face_image.show()\n",
    "text_photo_image = Image.fromarray(photo_text)\n",
    "draw = ImageDraw.Draw(text_photo_image)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 28, encoding=\"unic\")\n",
    "draw.rectangle(\n",
    "   (left, top, right, bottom),\n",
    "   outline=(0, 0, 255), width = 4)\n",
    "draw.text((left+100,bottom - 50), \"Text on Image\", font=font, fill=(255,128,0))\n",
    "text_photo_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bdb63",
   "metadata": {},
   "source": [
    "## Locate all faces in a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c257a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Faces detected in this photo 10\n",
      "Face,, 0  Top, Left, , Bottom, Right.. 153 275 201 322\n",
      "Face,, 1  Top, Left, , Bottom, Right.. 133 37 173 76\n",
      "Face,, 2  Top, Left, , Bottom, Right.. 139 409 186 456\n",
      "Face,, 3  Top, Left, , Bottom, Right.. 139 567 186 615\n",
      "Face,, 4  Top, Left, , Bottom, Right.. 144 174 191 221\n",
      "Face,, 5  Top, Left, , Bottom, Right.. 158 726 206 773\n",
      "Face,, 6  Top, Left, , Bottom, Right.. 133 117 173 156\n",
      "Face,, 7  Top, Left, , Bottom, Right.. 96 207 143 255\n",
      "Face,, 8  Top, Left, , Bottom, Right.. 133 353 173 392\n",
      "Face,, 9  Top, Left, , Bottom, Right.. 165 685 205 724\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "group_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Convert the group photo into a PIL Image\n",
    "group_pil_image = Image.fromarray(group_photo)\n",
    "\n",
    "# Find all the faces in the image \n",
    "fl = face_recognition.face_locations(group_photo, model = 'cnn')\n",
    "draw = ImageDraw.Draw(group_pil_image)\n",
    "\n",
    "\n",
    "\n",
    "# Let us print the number of faces in the Photo\n",
    "face_count = len(fl)\n",
    "print(\"No of Faces detected in this photo\", face_count)\n",
    "\n",
    "for i in range(face_count):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = fl[i]\n",
    "    print(\"Face,,\", i, \" Top, Left, , Bottom, Right..\", top, left, bottom, right)\n",
    "    # You can access the actual face itself like this:\n",
    "    draw.rectangle(\n",
    "            (left, top, right, bottom),\n",
    "            outline=(255, 0, 0), width=3)\n",
    "        \n",
    "group_pil_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e1ff8",
   "metadata": {},
   "source": [
    "## Writing name on all faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36db3961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Faces detected in this photo 10\n",
      "Face,, 0  Top, Left, , Bottom, Right.. 153 275 201 322\n",
      "Face,, 1  Top, Left, , Bottom, Right.. 133 37 173 76\n",
      "Face,, 2  Top, Left, , Bottom, Right.. 139 409 186 456\n",
      "Face,, 3  Top, Left, , Bottom, Right.. 139 567 186 615\n",
      "Face,, 4  Top, Left, , Bottom, Right.. 144 174 191 221\n",
      "Face,, 5  Top, Left, , Bottom, Right.. 158 726 206 773\n",
      "Face,, 6  Top, Left, , Bottom, Right.. 133 117 173 156\n",
      "Face,, 7  Top, Left, , Bottom, Right.. 96 207 143 255\n",
      "Face,, 8  Top, Left, , Bottom, Right.. 133 353 173 392\n",
      "Face,, 9  Top, Left, , Bottom, Right.. 165 685 205 724\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "grp_photo = face_recognition.load_image_file(\"./pics&group/group1.jpeg\")\n",
    "\n",
    "# Convert the group photo into a PIL Image\n",
    "grp_pil_image = Image.fromarray(grp_photo)\n",
    "\n",
    "# Find all the faces in the image \n",
    "fl = face_recognition.face_locations(grp_photo, model ='cnn')\n",
    "# Let us print the number of faces in the Photo\n",
    "face_count = len(fl)\n",
    "print(\"No of Faces detected in this photo\", face_count)\n",
    "\n",
    "draw = ImageDraw.Draw(grp_pil_image)\n",
    "\n",
    "fnt = ImageFont.truetype(\"calibri.ttf\", 28, encoding=\"unic\")\n",
    "# Let us print the number of faces in the Photo\n",
    "\n",
    "for i in range(face_count):\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = fl[i]\n",
    "    print(\"Face,,\", i, \" Top, Left, , Bottom, Right..\", top, left, bottom, right)\n",
    "    # You can access the actual face itself like this:\n",
    "    draw.rectangle(\n",
    "            (left, top, right, bottom),\n",
    "            outline=(255, 0, 0), width = 3)\n",
    "    draw.text((left,bottom-20), str(i), font=fnt, fill=(0,255,0))   \n",
    "grp_pil_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1a0b5",
   "metadata": {},
   "source": [
    "## Face encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4234a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the Encoding array is ... (128,)\n",
      "Now let us print the encoding\n",
      "[-2.11196303e-01  1.78484723e-01  1.11796908e-01 -3.69675346e-02\n",
      " -2.81905085e-02 -7.96913281e-02  2.95548178e-02 -6.80622309e-02\n",
      "  1.18464306e-01  3.97704542e-02  2.61571705e-01 -4.08349298e-02\n",
      " -2.01663181e-01 -1.86527967e-01  1.27971441e-01  1.42350957e-01\n",
      " -1.49539962e-01 -7.07360655e-02 -5.49269170e-02 -1.37426510e-01\n",
      "  1.79726519e-02  4.34840657e-02  4.31205854e-02  9.45459157e-02\n",
      " -3.19219604e-02 -4.02293891e-01 -8.23119879e-02 -1.75026685e-01\n",
      "  9.38636884e-02 -8.30285996e-02  4.03862819e-02  1.10961404e-02\n",
      " -2.03860983e-01 -6.13673441e-02 -4.40345928e-02  1.05566584e-01\n",
      "  2.47344486e-02 -2.93298531e-02  1.55784652e-01 -7.25218095e-04\n",
      " -8.27835128e-02 -4.86381724e-02 -2.85921860e-02  2.58049905e-01\n",
      "  1.73459381e-01 -2.19700485e-02  8.15376416e-02  3.18488553e-02\n",
      "  5.31721041e-02 -1.66757688e-01  1.08115096e-02  1.21095069e-01\n",
      "  1.49202660e-01  3.57866846e-02 -2.72658207e-02 -1.29513174e-01\n",
      " -2.14305073e-02  3.06825992e-02 -2.68639117e-01 -6.23787008e-03\n",
      "  4.09384035e-02 -1.01267800e-01 -1.44170463e-01  3.18438672e-02\n",
      "  2.99706817e-01  1.40618727e-01 -1.29726693e-01 -1.26570374e-01\n",
      "  1.63345605e-01 -1.02607056e-01  3.80423367e-02  8.59390125e-02\n",
      " -1.56206667e-01 -8.69053453e-02 -2.27369979e-01  1.58235371e-01\n",
      "  3.36202502e-01 -2.35818420e-03 -2.19868183e-01 -2.62590162e-02\n",
      " -2.59835005e-01  2.45624259e-02 -6.02696426e-02  3.28188203e-02\n",
      " -6.86261654e-02  1.88135281e-02 -1.52100682e-01  8.11169744e-02\n",
      "  7.62470067e-02 -5.84443957e-02  2.88371649e-02  2.46335030e-01\n",
      "  3.45875472e-02  6.64869770e-02 -9.36752837e-03  4.86240350e-02\n",
      " -4.36877944e-02 -3.84113677e-02 -2.95996778e-02 -4.21001874e-02\n",
      "  1.03185520e-01 -7.51372650e-02  7.29914056e-03  6.24471158e-02\n",
      " -2.41833836e-01  1.73316538e-01  4.42830585e-02 -4.67790430e-03\n",
      " -3.25601362e-03 -2.67865304e-02 -2.72489004e-02 -7.65059888e-02\n",
      "  1.70691982e-01 -2.20809340e-01  1.84101537e-01  1.95314333e-01\n",
      " -6.23104423e-02  1.68207467e-01 -2.57039033e-02  1.01060376e-01\n",
      " -5.30466437e-02 -1.05950266e-01 -1.00979976e-01  4.89451503e-03\n",
      "  5.12025580e-02 -1.90983992e-04 -5.21356277e-02  3.34438756e-02]\n"
     ]
    }
   ],
   "source": [
    "#Program to load a picture and find its face encoding\n",
    "import face_recognition\n",
    "photo_emma = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "encodings_emma = face_recognition.face_encodings(photo_emma)[0]\n",
    "print(\"The shapes of the Encoding array is ...\", encodings_emma.shape)\n",
    "print(\"Now let us print the encoding\")\n",
    "print(encodings_emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6866dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of faces  ... 8\n",
      "The shape of each encodings.. (128,)\n",
      "Now let us print the encoding\n",
      " Encodings of Face... 0\n",
      "[-5.01371808e-02  5.95846176e-02  3.84515002e-02 -7.95002133e-02\n",
      " -1.51385024e-01 -2.11636368e-02  2.81492248e-03  7.99112488e-03\n",
      "  1.99809715e-01 -1.19494110e-01  2.22855732e-01 -4.02088873e-02\n",
      " -2.64928579e-01  3.91888767e-02 -1.22234583e-01  8.17655772e-02\n",
      " -1.46829024e-01 -1.17950730e-01 -7.64902085e-02 -2.02289313e-01\n",
      "  9.31211375e-03  6.06852584e-03  1.16483786e-03  9.46590304e-02\n",
      " -2.03640878e-01 -2.35524803e-01 -6.19096123e-02 -1.27027124e-01\n",
      " -1.16387960e-02 -2.11862534e-01  1.05134748e-01  1.44716591e-01\n",
      " -1.48338616e-01 -7.46089965e-02 -5.21512516e-03  4.28706408e-03\n",
      "  5.30402549e-03 -1.55300573e-02  2.09073797e-01  1.94133129e-02\n",
      " -1.38774380e-01  9.02118012e-02  2.42942572e-02  3.68279845e-01\n",
      "  9.04522911e-02  2.92136725e-02 -3.52421030e-03 -3.32493186e-02\n",
      "  1.76388413e-01 -2.58855104e-01  5.82465306e-02  1.72631517e-01\n",
      "  1.20749600e-01 -1.70416255e-02  4.82877940e-02 -1.14172675e-01\n",
      "  3.22023407e-04  2.12084457e-01 -1.88979492e-01  1.48102239e-01\n",
      "  7.56759420e-02 -3.26975323e-02 -2.21505836e-02 -5.94218336e-02\n",
      "  9.37432051e-02  6.97135553e-02 -9.52865109e-02 -1.37527019e-01\n",
      "  1.59958720e-01 -1.43496826e-01 -3.03559154e-02  1.63408458e-01\n",
      " -1.30634487e-01 -1.96770787e-01 -1.68203399e-01  9.62553620e-02\n",
      "  4.10898030e-01  1.57255828e-01 -5.07387258e-02  5.76074887e-03\n",
      " -8.16898122e-02 -7.88008142e-03 -4.22939472e-02 -1.18807144e-02\n",
      " -1.52876049e-01 -5.58083467e-02 -6.06418326e-02  1.19905159e-01\n",
      "  1.81976482e-01  3.81011553e-02 -9.66050997e-02  2.12558731e-01\n",
      "  1.86819807e-02 -2.01909114e-02 -7.91650172e-03 -2.24220380e-03\n",
      " -1.69308051e-01  1.84587147e-02 -1.43318817e-01  6.30199257e-03\n",
      "  2.51878612e-02 -9.48947370e-02 -3.57337780e-02  5.81733175e-02\n",
      " -1.97450131e-01  1.43698514e-01 -7.10617378e-02 -5.53832389e-02\n",
      " -8.49661529e-02  1.05515487e-01 -1.37434199e-01  3.12610492e-02\n",
      "  2.12918907e-01 -2.54072726e-01  1.57737389e-01  1.93289801e-01\n",
      "  1.31789982e-01  9.74681228e-02  1.05211481e-01 -6.70230463e-02\n",
      "  6.20588474e-02 -6.00424930e-02 -1.34660915e-01 -1.11495748e-01\n",
      "  9.32122022e-02 -9.19972956e-02  7.19700456e-02 -2.81709135e-02]\n",
      " Encodings of Face... 1\n",
      "[-1.63426369e-01  9.93756950e-02  7.28360703e-03 -6.91477209e-02\n",
      " -1.66752294e-01  1.97864641e-02 -2.38941200e-02 -8.55860114e-02\n",
      "  1.49246871e-01 -1.04948925e-02  1.24661542e-01 -2.89661493e-02\n",
      " -2.82419562e-01  2.99435854e-02 -8.94265771e-02  5.30435145e-02\n",
      " -1.64736047e-01 -1.09156109e-01 -1.87931508e-02 -8.63997936e-02\n",
      "  1.31048679e-01 -3.16451527e-02  3.20103392e-02  1.05196267e-01\n",
      " -2.41005674e-01 -2.77123183e-01 -1.13155857e-01 -1.41318530e-01\n",
      " -6.60241768e-03 -9.86234695e-02  3.05427350e-02  2.32192092e-02\n",
      " -1.97116211e-01 -9.01586711e-02 -3.95475700e-02  9.56124067e-02\n",
      " -7.16952328e-03 -4.50374819e-02  1.87737390e-01  4.18266281e-04\n",
      " -1.17025942e-01  1.03059813e-01  3.18698660e-02  2.92330772e-01\n",
      "  1.69462800e-01  2.73405164e-02  1.28890648e-01 -1.24438219e-02\n",
      "  9.65536013e-02 -2.72523701e-01  5.72393313e-02  1.23542979e-01\n",
      "  1.43477365e-01 -3.92637588e-03  5.37184700e-02 -1.59830630e-01\n",
      " -1.09558962e-02  1.94965303e-01 -1.97704494e-01  1.71623319e-01\n",
      "  8.56548846e-02 -1.39172636e-02  5.53329848e-03  2.16692570e-04\n",
      "  2.28061363e-01  1.25385940e-01 -1.07472986e-01 -1.36823028e-01\n",
      "  2.17514366e-01 -1.35261267e-01 -5.67534454e-02  9.25997272e-02\n",
      " -1.30369738e-01 -1.85622036e-01 -2.34842405e-01  1.00509956e-01\n",
      "  4.63145763e-01  1.54427081e-01 -1.28388777e-01  4.95214462e-02\n",
      " -1.61906958e-01  3.03820036e-02 -2.39540357e-02 -1.06734075e-02\n",
      " -1.07201837e-01  2.36002021e-02 -1.31954968e-01  1.11812927e-01\n",
      "  2.35197991e-01  2.82939635e-02 -5.71758859e-02  2.53005743e-01\n",
      "  1.10036150e-01  1.00120082e-02  6.45672083e-02  4.51899841e-02\n",
      " -1.26309380e-01 -2.76466645e-02 -1.32479101e-01  1.57154649e-02\n",
      "  3.04081887e-02 -8.88336524e-02  2.20446475e-02  1.06560767e-01\n",
      " -1.90558761e-01  1.45260572e-01 -7.82215372e-02 -6.24618866e-02\n",
      " -1.55568868e-01  6.15262054e-03 -1.57846779e-01  9.05468464e-02\n",
      "  2.09283724e-01 -3.19921821e-01  1.50052890e-01  1.81395024e-01\n",
      "  5.56052886e-02  1.08100139e-01  8.62677619e-02 -5.25302850e-02\n",
      "  8.16782638e-02 -2.89765373e-03 -1.58055589e-01 -8.81633461e-02\n",
      "  8.41406062e-02 -9.56664383e-02  9.09188464e-02  8.38740617e-02]\n",
      " Encodings of Face... 2\n",
      "[-0.15336025  0.13995956  0.02661858 -0.09094325 -0.07512701  0.08420648\n",
      " -0.00593475 -0.0829904   0.2133268  -0.08299458  0.13897118  0.00730141\n",
      " -0.2710951   0.00773503 -0.02708047  0.07692757 -0.12078763 -0.17267716\n",
      " -0.06968544 -0.12668642  0.0861766  -0.04924726 -0.06226371 -0.00388636\n",
      " -0.18849531 -0.30264381 -0.05004729 -0.13846341  0.05225498 -0.12856944\n",
      "  0.10460077 -0.07005776 -0.21022244 -0.06428997 -0.03601125  0.11454699\n",
      " -0.04800653 -0.01916287  0.18702449 -0.07307839 -0.09387477  0.01867369\n",
      "  0.00733243  0.25769374  0.07720572  0.05182416  0.0883927  -0.06099637\n",
      "  0.10919572 -0.29705587  0.11900682  0.14182314  0.12112644  0.12075807\n",
      "  0.07373685 -0.19729039  0.02034236  0.12305705 -0.16623721  0.14899331\n",
      "  0.11590069  0.01698152 -0.05063435 -0.03542802  0.22048526  0.0483122\n",
      " -0.14184538 -0.09988111  0.10044391 -0.10597298  0.01387442  0.00617777\n",
      " -0.11887541 -0.18921755 -0.25078151  0.16461854  0.3787894   0.16549863\n",
      " -0.13551408 -0.00109965 -0.12874992  0.04845572 -0.01047706 -0.03557875\n",
      " -0.08874726 -0.01795962 -0.04273314  0.11379202  0.16768993 -0.02268946\n",
      " -0.01853588  0.16413541  0.00419631  0.00680112 -0.06004936  0.08664024\n",
      " -0.15813598 -0.00848854 -0.05873836  0.03026612  0.07935958 -0.03851157\n",
      "  0.04033246  0.11932877 -0.20855674  0.20699149 -0.06224791 -0.02611157\n",
      " -0.041819    0.05894099 -0.15139604 -0.02763664  0.2155959  -0.22745971\n",
      "  0.22178215  0.25608677 -0.00352963  0.13675657  0.1033716   0.02355621\n",
      "  0.06941606  0.07399046 -0.18483408 -0.0803635   0.02275534 -0.01980625\n",
      " -0.02059295  0.04668447]\n",
      " Encodings of Face... 3\n",
      "[-0.11638403  0.11842017  0.06359984 -0.06253326 -0.12350696  0.09151838\n",
      " -0.0042579   0.026479    0.10560111 -0.04421744  0.16418588  0.00773987\n",
      " -0.22305851 -0.00263341 -0.05635577  0.06989101 -0.14192054 -0.10209536\n",
      " -0.08838617 -0.04834769  0.04764658  0.01579486  0.04912456  0.05597073\n",
      " -0.21795468 -0.31763777 -0.0533319  -0.09436956 -0.0280782  -0.14963076\n",
      "  0.10626032  0.0167111  -0.22594805 -0.05690802 -0.08867241  0.02997482\n",
      " -0.05147818 -0.05401986  0.18329623  0.01318001 -0.13654536  0.08376355\n",
      "  0.03476566  0.3290897   0.11243197  0.02486714  0.03423062 -0.02819319\n",
      "  0.05544252 -0.26907331  0.09976819  0.12716492  0.12928784  0.05873824\n",
      "  0.05099885 -0.03948917  0.06115597  0.12169357 -0.15461375  0.06245458\n",
      "  0.01371169  0.09977025  0.08641243 -0.05130637  0.18055102  0.06040354\n",
      " -0.05983974 -0.08506455  0.06563281 -0.11961471 -0.05562749  0.08069014\n",
      " -0.08846404 -0.19197558 -0.26151139  0.11822691  0.33299226  0.20405771\n",
      " -0.15135707 -0.01121801 -0.12138686 -0.04116428  0.0193481   0.00960191\n",
      " -0.13183132 -0.00615403 -0.04846391  0.13397835  0.20966947  0.00419417\n",
      " -0.08492117  0.23844458  0.13402165 -0.06574365  0.04242541 -0.00528644\n",
      " -0.09519476  0.04973506 -0.14875209  0.05940316  0.02622642 -0.01566008\n",
      " -0.00368376  0.11060531 -0.19272229  0.15049052 -0.00431014 -0.09965157\n",
      " -0.00775271  0.09286306 -0.21786977 -0.07628751  0.16159719 -0.240119\n",
      "  0.10868058  0.18706031  0.02692827  0.09357603  0.15038705  0.03227598\n",
      "  0.02340506  0.04178564 -0.09787604 -0.04199222  0.16863863 -0.04506723\n",
      "  0.07649438  0.03260984]\n",
      " Encodings of Face... 4\n",
      "[-0.08119684  0.0952587   0.01766533  0.01980508 -0.02332177 -0.07409664\n",
      "  0.01813698 -0.11898412  0.13477518 -0.04359202  0.2704227  -0.03148179\n",
      " -0.23960088 -0.13854277 -0.02873069  0.14556912 -0.17774698 -0.10715636\n",
      " -0.0363731  -0.12193131  0.0307086   0.01071523  0.01158045  0.13065554\n",
      " -0.12279727 -0.31453818 -0.07687207 -0.21793973  0.04027354 -0.12977012\n",
      " -0.03908916  0.12297189 -0.16360018 -0.09063851 -0.03481332 -0.02112534\n",
      "  0.09309887  0.07149395  0.22491735  0.1351919  -0.11369739 -0.01217667\n",
      " -0.06688228  0.33501351  0.12403941 -0.02059248  0.09297389  0.0182004\n",
      "  0.09108151 -0.15715246 -0.01253902  0.10656183  0.2739301  -0.00689664\n",
      " -0.01655762 -0.17011485 -0.0952573   0.05063301 -0.1938248   0.13718453\n",
      "  0.03626043 -0.12989992 -0.07446685 -0.02896011  0.23833494  0.02148546\n",
      " -0.09424394 -0.09107965  0.23833023 -0.07427853 -0.05981764  0.06688146\n",
      " -0.138447   -0.14387533 -0.25932467  0.06799527  0.34374419  0.07750316\n",
      " -0.23349264  0.02449697 -0.21334288 -0.02001533 -0.0301299   0.02503005\n",
      " -0.02910509  0.07337423 -0.06930031  0.03457852  0.12406925 -0.02748462\n",
      " -0.04897772  0.19209529 -0.05807428  0.10796961  0.01475564 -0.04402118\n",
      " -0.06007171  0.00570324 -0.05654257  0.01440183 -0.03699671 -0.10469001\n",
      "  0.01565655  0.00514189 -0.19494419  0.13813418  0.01395918 -0.01833737\n",
      " -0.09066999  0.08405086 -0.13792603  0.00896857  0.21157774 -0.28297848\n",
      "  0.23596714  0.21568853  0.03022379  0.12405711  0.00755275 -0.00409902\n",
      " -0.02990967 -0.07639186 -0.16360968 -0.08626454  0.14080299 -0.11567962\n",
      "  0.03472106  0.0092062 ]\n",
      " Encodings of Face... 5\n",
      "[-3.30039114e-02  5.07632047e-02  8.03232752e-03 -1.44162513e-02\n",
      " -4.11091000e-02  6.11950457e-02 -2.16737539e-02 -2.76924744e-02\n",
      "  1.75204083e-01 -5.60281128e-02  1.25528991e-01 -2.11926363e-03\n",
      " -2.56974012e-01  1.42863281e-02 -1.01305991e-01  7.84557462e-02\n",
      " -1.68224797e-01 -9.23883021e-02 -6.34047389e-02 -6.59735203e-02\n",
      "  2.58130897e-02  2.03182213e-02 -2.19127797e-02  3.02629359e-02\n",
      " -1.72009230e-01 -2.74651438e-01 -4.66004275e-02 -1.44280329e-01\n",
      " -5.67178279e-02 -1.33071810e-01  5.39225750e-02  1.36220871e-04\n",
      " -1.99875519e-01  1.41378380e-02 -7.13945180e-02 -2.67289989e-02\n",
      " -3.82109657e-02  4.31973487e-03  2.37150788e-01  4.67235744e-02\n",
      " -1.21046685e-01  4.02861536e-02  2.25169268e-02  2.96948165e-01\n",
      "  1.21546686e-01 -4.05356884e-02  5.05502038e-02 -2.83225607e-02\n",
      "  1.40934065e-01 -3.36026996e-01  6.72381371e-02  1.42483532e-01\n",
      "  1.17440134e-01  9.89391506e-02  5.76152019e-02 -1.61337391e-01\n",
      " -2.14725398e-02  1.52781829e-01 -1.76875234e-01  1.91903591e-01\n",
      "  6.11971840e-02  2.01775804e-02 -2.59152967e-02  2.67811976e-02\n",
      "  1.85207486e-01  8.78052264e-02 -1.27529293e-01 -1.35662764e-01\n",
      "  9.73581299e-02 -1.46617740e-01  3.83044630e-02  1.07853718e-01\n",
      " -4.66902219e-02 -2.48158306e-01 -2.29106680e-01  1.05891295e-01\n",
      "  3.53524059e-01  1.37475863e-01 -1.38432637e-01  2.07078774e-02\n",
      " -1.72913343e-01 -2.10894253e-02  6.07367083e-02 -3.67712937e-02\n",
      " -4.49599698e-02  2.37550903e-02 -8.23670775e-02  1.18274279e-01\n",
      "  1.87667578e-01 -6.82726689e-03 -2.56653391e-02  2.29661956e-01\n",
      "  2.29641479e-02 -3.45104672e-02 -1.62466653e-02  9.10381675e-02\n",
      " -1.02714702e-01  2.70272940e-02 -9.30776969e-02  9.50053707e-02\n",
      "  2.43260488e-02 -7.70868734e-02  2.85136327e-02  1.62662156e-02\n",
      " -1.70368820e-01  1.89256310e-01 -1.10113639e-02 -4.95141149e-02\n",
      " -4.93276753e-02  1.79341417e-02 -1.62838623e-01  4.40134518e-02\n",
      "  2.00773895e-01 -3.36699635e-01  2.04136938e-01  9.53323916e-02\n",
      "  3.55482101e-03  1.45598024e-01  1.05605125e-02  2.24357396e-02\n",
      " -1.71494260e-02 -4.74436544e-02 -1.43521354e-01 -5.87794557e-02\n",
      "  1.97222754e-02  3.64172179e-03  1.37337726e-02  2.88473796e-02]\n",
      " Encodings of Face... 6\n",
      "[-0.08793304  0.12476855  0.02881577 -0.02926105 -0.02494201 -0.08687834\n",
      " -0.08040094 -0.09808974  0.12671246 -0.03773882  0.22045267 -0.03589995\n",
      " -0.22726703 -0.16581686  0.01753641  0.11007444 -0.11734048 -0.13410531\n",
      " -0.04570571 -0.05686727  0.07214355 -0.03480374  0.01067906  0.05643336\n",
      " -0.21421762 -0.40738291 -0.06732776 -0.04894237 -0.05038034 -0.03046328\n",
      " -0.007113    0.15845954 -0.17619976 -0.04156459  0.02058     0.081724\n",
      " -0.00797579  0.05280028  0.18252535  0.0456094  -0.17137942  0.01998106\n",
      " -0.0044053   0.26643714  0.1958237   0.00318205  0.06628768 -0.00872327\n",
      "  0.11747926 -0.23799095  0.03890568  0.22517204  0.13964088  0.01852551\n",
      "  0.09277996 -0.07752304 -0.02173001  0.14711237 -0.24995653  0.04007943\n",
      " -0.00653585 -0.07467259 -0.09764005 -0.05741504  0.13882847  0.17705716\n",
      " -0.10298949 -0.1026061   0.18658213 -0.10510623 -0.04177513  0.02229498\n",
      " -0.12256058 -0.23142099 -0.29201275  0.06154925  0.31124917  0.14610954\n",
      " -0.22222963  0.06310582 -0.0502879  -0.01239325  0.04812532 -0.06085809\n",
      " -0.14742807  0.02692765 -0.07698322  0.05809526  0.1661296   0.04307441\n",
      " -0.04890063  0.23239116 -0.01174302  0.0697628   0.07783851  0.00562323\n",
      " -0.06012231 -0.01766049 -0.17795187 -0.02263674  0.08176766 -0.1325136\n",
      "  0.01611044  0.05705643 -0.18325949  0.15510836  0.02865009  0.03413557\n",
      " -0.02791125  0.08128285 -0.1549245  -0.02273396  0.1312843  -0.21934876\n",
      "  0.23238444  0.14328164  0.02281627  0.12679514  0.11282232 -0.01496433\n",
      " -0.00752345 -0.08044785 -0.0811675  -0.09856744  0.10322316 -0.01788279\n",
      "  0.0658468   0.01931236]\n",
      " Encodings of Face... 7\n",
      "[-0.09184498  0.17980622  0.11067285 -0.00749857 -0.03151605 -0.04648189\n",
      " -0.01347017 -0.00860484  0.11366204  0.04750544  0.16670991 -0.06173725\n",
      " -0.24001761 -0.11444034 -0.02308545  0.13789922 -0.19264375 -0.15808785\n",
      " -0.03002858 -0.0228593   0.07520729  0.05343419  0.05526436  0.11244889\n",
      " -0.1243339  -0.36250433 -0.01882195 -0.10282517 -0.02099918 -0.09028924\n",
      " -0.04093133  0.11475709 -0.1607549  -0.02333302  0.03153045  0.07281031\n",
      "  0.05947639 -0.00656497  0.14341742  0.07912754 -0.13614097  0.05780314\n",
      " -0.01933038  0.32731959  0.12353219  0.03725431  0.06715044 -0.03154217\n",
      "  0.12470467 -0.22100453  0.06468074  0.21741222  0.14671053 -0.02660734\n",
      "  0.08680224 -0.12900363 -0.0320204   0.10849094 -0.16745146  0.11005526\n",
      "  0.03556686 -0.01792999 -0.01710929 -0.1302727   0.13124645  0.052424\n",
      " -0.10558131 -0.10900908  0.09407423 -0.07315973 -0.06199016  0.0762818\n",
      " -0.1272095  -0.1429498  -0.23354913  0.06980611  0.33828884  0.0949886\n",
      " -0.2246048   0.02322488 -0.09321676  0.00458946 -0.03089264  0.05875975\n",
      " -0.15671156  0.06685996 -0.15393852  0.03500754  0.13473524  0.02363812\n",
      " -0.02351953  0.22104082  0.0030003   0.04605023  0.01112629 -0.05736616\n",
      " -0.07009131  0.02344579 -0.11345672 -0.01595314 -0.01146731 -0.12180801\n",
      " -0.07065651  0.04436022 -0.19812903  0.0467382  -0.00702002 -0.01074829\n",
      " -0.05371094  0.07908852 -0.14316641 -0.0329839   0.12904713 -0.25417918\n",
      "  0.14046858  0.18424287  0.05086297  0.08972882  0.04133157  0.0559568\n",
      " -0.00475542 -0.04129701 -0.0651377  -0.07525846  0.14646438 -0.03246104\n",
      "  0.00465343  0.00714686]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "photo_gr = face_recognition.load_image_file('./pics&group/group1.jpeg','RGB')\n",
    "encodings_gr = face_recognition.face_encodings(photo_gr)\n",
    "print(\"The Number of faces  ...\", len(encodings_gr))\n",
    "print(\"The shape of each encodings..\", encodings_gr[0].shape)\n",
    "print(\"Now let us print the encoding\")\n",
    "for i in range(len(encodings_gr)):\n",
    "    print(\" Encodings of Face...\", i)\n",
    "    print(encodings_gr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957a65",
   "metadata": {},
   "source": [
    "## Distance Function and Resemblance of Faces\n",
    "\n",
    "The purpose of encoding is to find a unique signature for a face. If we consider two face photos of the same person and find out the encodings of each photo. The two encodings are almost same. This means that the Euclidean distance between them is as small as less than 0.6. If the two encodings are for two different person's photos, the distance is more than 0.6. \n",
    "People with resemblance have encodings with distances small and people with totally difference face appearances have encodings of distance high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b96a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between the two photos  [0.40638764]\n"
     ]
    }
   ],
   "source": [
    "#Program to find distance between faces\n",
    "import face_recognition\n",
    "photo_recog1 = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "encodings_recog1 = face_recognition.face_encodings(photo_recog1)[0]\n",
    "\n",
    "photo_recog2 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "encodings_recog2 = face_recognition.face_encodings(photo_recog2)[0]\n",
    "dist = face_recognition.face_distance([encodings_recog1],encodings_recog2)\n",
    "print(\"Distance between the two photos \", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a1b14",
   "metadata": {},
   "source": [
    "## Distance between multiple photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7323726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: pic1 to pic2, pic3, pic4,  and pic5 respectively\n",
      "[0.40638764 0.38324746 0.32724422 0.41067434]\n"
     ]
    }
   ],
   "source": [
    "#Program to load a picture and find its face encoding of same person\n",
    "import face_recognition\n",
    "fa = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "f0 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "f1 = face_recognition.load_image_file('./pics&group/pic3.jpeg','RGB')\n",
    "f2 = face_recognition.load_image_file('./pics&group/pic4.jpeg','RGB')\n",
    "f3 = face_recognition.load_image_file('./pics&group/pic5.jpeg','RGB')\n",
    "\n",
    "fa_sign = face_recognition.face_encodings(fa)[0]\n",
    "f0_sign = face_recognition.face_encodings(f0)[0]\n",
    "f1_sign = face_recognition.face_encodings(f1)[0]\n",
    "f2_sign = face_recognition.face_encodings(f2)[0]\n",
    "f3_sign = face_recognition.face_encodings(f3)[0]\n",
    "\n",
    "\n",
    "faces = [f0_sign, f1_sign, f2_sign, f3_sign ]\n",
    "dist = face_recognition.face_distance(faces,fa_sign)\n",
    "print(\"Distance: pic1 to pic2, pic3, pic4,  and pic5 respectively\")\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22301bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance 1 to 2  [0.6686964]\n",
      "Distance 2 to 3  [0.71448367]\n",
      "Distance 3 to 4  [0.78403007]\n",
      "Distance 4 to 5  [0.89384318]\n",
      "Distance 5 to 1  [0.89317529]\n"
     ]
    }
   ],
   "source": [
    "#Program to load five photos of different person\n",
    "import face_recognition\n",
    "#Load the five photos of the different person\n",
    "celebrit1 = face_recognition.load_image_file('./face_recog/celebrit1.jpg','RGB')\n",
    "celebrit2 = face_recognition.load_image_file('./face_recog/celebrit2.jpg','RGB')\n",
    "celebrit3 = face_recognition.load_image_file('./face_recog/celebrit3.jpg','RGB')\n",
    "celebrit4 = face_recognition.load_image_file('./face_recog/celebrit4.jpg','RGB')\n",
    "celebrit5 = face_recognition.load_image_file('./face_recog/celebrit5.jpg','RGB')\n",
    "\n",
    "#Let us find the encodings for each of the five faces\n",
    "encodings_celebrit1 = face_recognition.face_encodings(celebrit1)[0]\n",
    "encodings_celebrit2 = face_recognition.face_encodings(celebrit2)[0]\n",
    "encodings_celebrit3 = face_recognition.face_encodings(celebrit3)[0]\n",
    "encodings_celebrit4 = face_recognition.face_encodings(celebrit4)[0]\n",
    "encodings_celebrit5 = face_recognition.face_encodings(celebrit5)[0]\n",
    "\n",
    "# Let us find the distances between faces\n",
    "dist01_02 = face_recognition.face_distance([encodings_celebrit1],encodings_celebrit2)\n",
    "dist02_03 = face_recognition.face_distance([encodings_celebrit2],encodings_celebrit3)\n",
    "dist03_04 = face_recognition.face_distance([encodings_celebrit3],encodings_celebrit4)\n",
    "dist04_05 = face_recognition.face_distance([encodings_celebrit4],encodings_celebrit5)\n",
    "dist05_01 = face_recognition.face_distance([encodings_celebrit5],encodings_celebrit1)\n",
    "print(\"Distance 1 to 2 \", dist01_02)\n",
    "print(\"Distance 2 to 3 \", dist02_03)\n",
    "print(\"Distance 3 to 4 \", dist03_04)\n",
    "print(\"Distance 4 to 5 \", dist04_05)\n",
    "print(\"Distance 5 to 1 \", dist05_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aac123",
   "metadata": {},
   "source": [
    "## Face mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a62dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance: Son 0 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.72990638 0.79360617 0.74602903 0.70046816 0.83568435 0.93820042]\n",
      "\n",
      "Distance: Son 1 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.68449085 0.67372911 0.7230144  0.66845835 0.7651907  0.82157798]\n",
      "\n",
      "Distance: Son 2 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.84429839 0.7744297  0.71290187 0.80236541 0.78670347 0.88211748]\n",
      "\n",
      "Distance: Son 3 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.77117768 0.81288294 0.77629569 0.68695563 0.84930817 0.98030858]\n",
      "\n",
      "Distance: Son 4 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.77196765 0.80404854 0.86240018 0.87669905 0.64447716 0.77138433]\n",
      "\n",
      "Distance: Son 5 to Fathers 0, 1, 2, 3, 4, 5\n",
      "[0.84356954 0.83386023 0.83312569 0.81627252 0.80699236 0.73860243]\n"
     ]
    }
   ],
   "source": [
    "#Father to Son face mapping\n",
    "# Python program to recognize the photo of a son and map to\n",
    "# the father depending upon the resemblance.\n",
    "\n",
    "import face_recognition\n",
    "n = 6\n",
    "photo_father =[]\n",
    "encodings_father = []\n",
    "photo_son = []\n",
    "encodings_son = []\n",
    "for i in range(n):\n",
    "    f_path_template = './father/father0{}.png'\n",
    "    f_path = f_path_template.format(i)\n",
    "    photo_father.append(face_recognition.load_image_file(f_path,'RGB'))\n",
    "    encodings_father.append(face_recognition.face_encodings(photo_father[i])[0])\n",
    "    \n",
    "    s_path_template = './son/son0{}.png'\n",
    "    s_path = s_path_template.format(i)\n",
    "    photo_son.append(face_recognition.load_image_file(s_path,'RGB'))\n",
    "    encodings_son.append(face_recognition.face_encodings(photo_son[i])[0])\n",
    "    \n",
    "for i in range(6):\n",
    "    a = \"\\nDistance: Son {} to Fathers 0, 1, 2, 3, 4, 5\"\n",
    "    print(a.format(i))\n",
    "    print(face_recognition.face_distance(encodings_father, encodings_son[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f18c8",
   "metadata": {},
   "source": [
    "## Face Recognition – Compare method\n",
    "\n",
    "In this method, compare_ faces() is used to\n",
    "compare faces and recognize the faces.\n",
    "\n",
    "The input parameters are:\n",
    "1. A list of known face encodings\n",
    "2. One unknown face encoding\n",
    "The unknown face is compared with each of the known face fi in the List and a\n",
    "Boolean value found(i) is created whether they match or not. The Boolean list found is\n",
    "returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c392212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Emmanuel \n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "image_emman = face_recognition.load_image_file('./pics&group/pic1.jpeg')\n",
    "emman_encod = face_recognition.face_encodings(image_emman)[0]\n",
    "\n",
    "image_em = face_recognition.load_image_file('./pics&group/pic5.jpeg')\n",
    "em_encod = face_recognition.face_encodings(image_em)[0]\n",
    "results = face_recognition.compare_faces([emman_encod], em_encod, tolerance = 0.5)\n",
    "if results[0]:\n",
    "    print(\"This is Emmanuel \")\n",
    "else:\n",
    "    print('This is NOT Emmanuel ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "675abe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is NOT Emmanuel \n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "image_emman = face_recognition.load_image_file('./pics&group/pic1.jpeg')\n",
    "emman_encod = face_recognition.face_encodings(image_emman)[0]\n",
    "\n",
    "image_em = face_recognition.load_image_file('./pics&group/pic6.jpeg')\n",
    "em_encod = face_recognition.face_encodings(image_em)[0]\n",
    "results = face_recognition.compare_faces([emman_encod], em_encod, tolerance = 0.5)\n",
    "if results[0]:\n",
    "    print(\"This is Emmanuel \")\n",
    "else:\n",
    "    print('This is NOT Emmanuel ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45fede",
   "metadata": {},
   "source": [
    "## Face compare among unknown pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1914d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "pict_1 = face_recognition.load_image_file('./face_recog/celebrit1.jpg','RGB')\n",
    "pict_2 = face_recognition.load_image_file('./face_recog/celebrit2.jpg','RGB')\n",
    "pict_3 = face_recognition.load_image_file('./face_recog/celebrit3.jpg','RGB')\n",
    "pict_4 = face_recognition.load_image_file('./face_recog/celebrit4.jpg','RGB')\n",
    "pict_5 = face_recognition.load_image_file('./face_recog/celebrit5.jpg','RGB')\n",
    "pict_6 = face_recognition.load_image_file('./face_recog/pic3.jpeg','RGB')\n",
    "pict_unkwn = face_recognition.load_image_file('./pics&group/unknown.jpeg','RGB')\n",
    "\n",
    "pict_unkwn_sign = face_recognition.face_encodings(pict_unkwn)[0]\n",
    "pict1_sign = face_recognition.face_encodings(pict_1)[0]\n",
    "pict2_sign = face_recognition.face_encodings(pict_2)[0]\n",
    "pict3_sign = face_recognition.face_encodings(pict_3)[0]\n",
    "pict4_sign = face_recognition.face_encodings(pict_4)[0]\n",
    "pict5_sign = face_recognition.face_encodings(pict_5)[0]\n",
    "pict6_sign = face_recognition.face_encodings(pict_6)[0]\n",
    "\n",
    "faces = [pict1_sign, pict2_sign, pict3_sign, pict4_sign, pict5_sign, pict6_sign ]\n",
    "\n",
    "compare_fnd = face_recognition.compare_faces(faces,pict_unkwn_sign, tolerance = 0.4)\n",
    "\n",
    "print(\"Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\")\n",
    "print(compare_fnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67303b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\n",
      "[False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "pict_1 = face_recognition.load_image_file('./face_recog/celebrit1.jpg','RGB')\n",
    "pict_2 = face_recognition.load_image_file('./face_recog/celebrit2.jpg','RGB')\n",
    "pict_3 = face_recognition.load_image_file('./face_recog/celebrit3.jpg','RGB')\n",
    "pict_4 = face_recognition.load_image_file('./face_recog/celebrit4.jpg','RGB')\n",
    "pict_5 = face_recognition.load_image_file('./face_recog/celebrit5.jpg','RGB')\n",
    "pict_6 = face_recognition.load_image_file('./face_recog/pic3.jpeg','RGB')\n",
    "pict_unkwn = face_recognition.load_image_file('./pics&group/pic6.jpeg','RGB')\n",
    "\n",
    "pict_unkwn_sign = face_recognition.face_encodings(pict_unkwn)[0]\n",
    "pict1_sign = face_recognition.face_encodings(pict_1)[0]\n",
    "pict2_sign = face_recognition.face_encodings(pict_2)[0]\n",
    "pict3_sign = face_recognition.face_encodings(pict_3)[0]\n",
    "pict4_sign = face_recognition.face_encodings(pict_4)[0]\n",
    "pict5_sign = face_recognition.face_encodings(pict_5)[0]\n",
    "pict6_sign = face_recognition.face_encodings(pict_6)[0]\n",
    "\n",
    "faces = [pict1_sign, pict2_sign, pict3_sign, pict4_sign, pict5_sign, pict6_sign ]\n",
    "\n",
    "compare_fnd = face_recognition.compare_faces(faces,pict_unkwn_sign, tolerance = 0.4)\n",
    "\n",
    "print(\"Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\")\n",
    "print(compare_fnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c887d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\n",
      "[True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "pict_1 = face_recognition.load_image_file('./pics&group/pic1.jpeg','RGB')\n",
    "pict_2 = face_recognition.load_image_file('./pics&group/pic2.jpeg','RGB')\n",
    "pict_3 = face_recognition.load_image_file('./pics&group/pic3.jpeg','RGB')\n",
    "pict_4 = face_recognition.load_image_file('./pics&group/pic4.jpeg','RGB')\n",
    "pict_5 = face_recognition.load_image_file('./pics&group/pic5.jpeg','RGB')\n",
    "pict_6 = face_recognition.load_image_file('./pics&group/pic6.jpeg','RGB')\n",
    "pict_unkwn = face_recognition.load_image_file('./pics&group/unknown.jpeg','RGB')\n",
    "\n",
    "pict_unkwn_sign = face_recognition.face_encodings(pict_unkwn)[0]\n",
    "pict1_sign = face_recognition.face_encodings(pict_1)[0]\n",
    "pict2_sign = face_recognition.face_encodings(pict_2)[0]\n",
    "pict3_sign = face_recognition.face_encodings(pict_3)[0]\n",
    "pict4_sign = face_recognition.face_encodings(pict_4)[0]\n",
    "pict5_sign = face_recognition.face_encodings(pict_5)[0]\n",
    "pict6_sign = face_recognition.face_encodings(pict_6)[0]\n",
    "\n",
    "faces = [pict1_sign, pict2_sign, pict3_sign, pict4_sign, pict5_sign, pict6_sign ]\n",
    "\n",
    "compare_fnd = face_recognition.compare_faces(faces,pict_unkwn_sign, tolerance = 0.4)\n",
    "\n",
    "print(\"Compare Matches:pict1, pict2, pict3, pict4, pict5, pict6\")\n",
    "print(compare_fnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ba227",
   "metadata": {},
   "source": [
    "## Image Data storage and compare using Python Pandas CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7329eea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee           Name                   File Name\n",
      "0       201      Anne mark  ./face_recog/celebrit1.jpg\n",
      "1       202  Adesanya kemi  ./face_recog/celebrit2.jpg\n",
      "2       203      Alao nike  ./face_recog/celebrit3.jpg\n",
      "3       204    Badmus tolu  ./face_recog/celebrit4.jpg\n",
      "4       205   Phillip tope  ./face_recog/celebrit5.jpg\n",
      "5       206    Praise seun      ./face_recog/pic3.jpeg\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import face_recognition\n",
    "f = pd.read_csv('./database/Data.csv')\n",
    "print(f.to_string())\n",
    "empno = f[\"Employee\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "ukwn= face_recognition.load_image_file(\"./pics&group/pic1.jpeg\")\n",
    "ukwn_encod = face_recognition.face_encodings(ukwn)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "found = face_recognition.compare_faces(emp_encod, ukwn_encod, tolerance = 0.5)    \n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b69cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee           Name                   File Name\n",
      "0       201      Anne mark  ./face_recog/celebrit1.jpg\n",
      "1       202  Adesanya kemi  ./face_recog/celebrit2.jpg\n",
      "2       203      Alao nike  ./face_recog/celebrit3.jpg\n",
      "3       204    Badmus tolu  ./face_recog/celebrit4.jpg\n",
      "4       205   Phillip tope  ./face_recog/celebrit5.jpg\n",
      "5       206    Praise seun      ./face_recog/pic3.jpeg\n",
      "(1024, 769, 3)\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import face_recognition\n",
    "fnt = ImageFont.truetype(\"calibri.ttf\", 60, encoding=\"unic\")\n",
    "\n",
    "f = pd.read_csv('./database/Data.csv')\n",
    "\n",
    "print(f.to_string())\n",
    "empno = f[\"Employee\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "ukwn= face_recognition.load_image_file(\"./pics&group/pic2.jpeg\")\n",
    "print(ukwn.shape)\n",
    "ukwn_encod = face_recognition.face_encodings(ukwn)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "    \n",
    "found = face_recognition.compare_faces(emp_encod,ukwn_encod, tolerance = 0.4)    \n",
    "print(found)\n",
    "for i in range(n):\n",
    "    if found[i]:\n",
    "    \n",
    "        left = 100\n",
    "        bottom = ukwn.shape[0]\n",
    "        pil_ukwn = Image.fromarray(ukwn)\n",
    "        draw = ImageDraw.Draw(pil_ukwn)\n",
    "        draw.text((left,bottom - 250), name[i], font=fnt, fill=(255,0,0))\n",
    "        pil_ukwn.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decfd8ae",
   "metadata": {},
   "source": [
    "## Attendance Recording in a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee532039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee           Name                   File Name\n",
      "0       201      Anne mark  ./face_recog/celebrit1.jpg\n",
      "1       202  Adesanya kemi  ./face_recog/celebrit2.jpg\n",
      "2       203      Alao nike  ./face_recog/celebrit3.jpg\n",
      "3       204    Badmus tolu  ./face_recog/celebrit4.jpg\n",
      "4       205   Phillip tope  ./face_recog/celebrit5.jpg\n",
      "5       206    Praise seun      ./face_recog/pic3.jpeg\n",
      "(1024, 769, 3)\n",
      "[False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import face_recognition\n",
    "f = pd.read_csv('./database/Data.csv')\n",
    "print(f.to_string())\n",
    "empno = f[\"Employee\"].tolist()\n",
    "name = f[\"Name\"].tolist()\n",
    "filename = f[\"File Name\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "ukwn= face_recognition.load_image_file(\"./pics&group/pic3.jpeg\")\n",
    "print(ukwn.shape)\n",
    "ukwn_encod = face_recognition.face_encodings(ukwn)[0]\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(filename[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "    \n",
    "found = face_recognition.compare_faces(emp_encod,ukwn_encod, tolerance = 0.4)    \n",
    "print(found)\n",
    "for i in range(n):\n",
    "    if found[i]:\n",
    "        x = str(datetime.datetime.now())\n",
    "        attend = \"\\n\"+str(empno[i])+' '+str(name[i]+' '+x)\n",
    "        f = open(\"Attendance.txt\", \"a\")\n",
    "        f.write(attend)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5728c",
   "metadata": {},
   "source": [
    "## Image capture using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255a7dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n",
      "True (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    print(return_value, image.shape)\n",
    "    cv2.imwrite('photo'+str(i)+'.png', image)\n",
    "del(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1a36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./database/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4307b9",
   "metadata": {},
   "source": [
    "## Time and Date Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61271887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "206 seun Praise  2021-09-13 14:23:13.424349\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "empno = [201, 202, 203, 204, 205, 206, 207,208]\n",
    "fname = [\"mark\", \"kemi\", \"nike\", \"tolu\", \"tope\", \"seun\"]\n",
    "lname = [\"Anne\", \"Adesanya\",\"Alao\", \"Badmus\", \"Phillip\", \"Praise\"]\n",
    "x = str(datetime.datetime.now())\n",
    "i= 5\n",
    "attendancerecord = \"\\n\"+str(empno[i])+\" \"+fname[i]+\" \"+ lname[i]+\"  \"+x\n",
    "print(attendancerecord)\n",
    "f = open(\"./Attendance.txt\", \"a\")\n",
    "f.write(attendancerecord)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b32a6",
   "metadata": {},
   "source": [
    "## Playing audio file from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b61c3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"./database/audio_files/seun.mp3\")\n",
    "pygame.mixer.music.queue(\"./database/audio_files/Success.mp3\")\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b1eba",
   "metadata": {},
   "source": [
    "## Project Work - Employee Attendance Management System\n",
    "\n",
    "In this project work I develop an end-to-end attendance management system that uses Face Recognition.\n",
    "\n",
    "## High Level Design\n",
    "The following are the key modules:\n",
    "1. Reference Data load Module\n",
    "2. Face Capture and Store temporarily\n",
    "3. Face Recognition\n",
    "4. Attendance Record Module\n",
    "5. Display Attendance Module\n",
    "6. Announce Attendance Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfa15abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, True, False]\n",
      "4\n",
      "\n",
      "205 tope Phillip  2021-09-13 14:27:40.479622\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pygame\n",
    "\n",
    "# Module 1 Reference Data Load Module\n",
    "ef = pd.read_csv('./database/Employee.csv')\n",
    "empno = ef[\"Employee No\"].tolist()\n",
    "firstname = ef[\"First Name\"].tolist()\n",
    "lastname = ef[\"Last Name\"].tolist()\n",
    "photolocation = ef[\"Photo Location\"].tolist()\n",
    "audiolocation = ef[\"Audio Location\"].tolist()\n",
    "n = len(empno)\n",
    "emp = []\n",
    "emp_encod = []\n",
    "audio = []\n",
    "for i in range(n):\n",
    "    emp.append(face_recognition.load_image_file(photolocation[i]))\n",
    "    emp_encod.append(face_recognition.face_encodings(emp[i])[0])\n",
    "\n",
    "\n",
    "# Module 2 Face Image Capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "for i in range(10):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('Employee'+str(i)+'.png', image)\n",
    "del(camera)\n",
    "ukwn =face_recognition.load_image_file('Employee5.png')\n",
    "\n",
    "\n",
    "#Module 3 Face Recognition Module\n",
    "def identify_employee(photo):\n",
    "    try:\n",
    "        ukwn_encode = face_recognition.face_encodings(photo)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        sys.exit(1)\n",
    "    found = face_recognition.compare_faces(\n",
    "                emp_encod, ukwn_encode, tolerance = 0.4)    \n",
    "    print(found)\n",
    "    \n",
    "    index = -1\n",
    "    for i in range(n):\n",
    "        if found[i]:\n",
    "            index = i\n",
    "    return(index)\n",
    "\n",
    "emp_index = identify_employee(ukwn)    \n",
    "print(emp_index)   \n",
    "\n",
    "\n",
    "# Module 4 Attendance record in a data file attendance.txt\n",
    "if (emp_index != -1):\n",
    "    name =\"Face NOT Recognized\"\n",
    "    x = str(datetime.datetime.now())\n",
    "    eno = str(empno[emp_index])\n",
    "    f = firstname[emp_index]\n",
    "    l = lastname[emp_index]\n",
    "    ar = \"\\n\"+eno+\" \"+f+\" \"+ l+ \"  \"+x\n",
    "    f = open(\"./Attendance.txt\", \"a\")\n",
    "    f.write(ar)\n",
    "    f.close()  \n",
    "    print(ar)\n",
    "    \n",
    "    \n",
    "# Module 5 Display Attendance Module\n",
    "pil_ukwn = Image.fromarray(ukwn)\n",
    "draw = ImageDraw.Draw(pil_ukwn)\n",
    "fnt = ImageFont.truetype(\"calibri.ttf\", 60, encoding=\"unic\")\n",
    "\n",
    "if emp_index ==-1:\n",
    "    name =\"Face NOT Recognized\"\n",
    "else:\n",
    "    name = firstname[emp_index]+\" \"+lastname[emp_index]\n",
    "x = 100\n",
    "y = ukwn.shape[0] - 100\n",
    "draw.text((x, y), name, font=fnt, fill=(255,0,0))\n",
    "pil_ukwn.show()\n",
    "\n",
    "\n",
    "# Module 6 Announce Attendance Recorded Module\n",
    "audioloc = audiolocation[emp_index]\n",
    "pygame.mixer.init()\n",
    "if emp_index ==-1:\n",
    "    pygame.mixer.music.load(\"./database/audio_files/not_recog.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "else:\n",
    "    pygame.mixer.music.load(audioloc)\n",
    "    pygame.mixer.music.play()\n",
    "    pygame.mixer.music.queue(\"./database/audio_files/success.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855fded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c21c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70078413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37973f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
